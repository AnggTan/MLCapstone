{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q scann"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuApZpUIOl1X",
        "outputId": "c2392389-1c93-4238-f149-7987cc9b1c6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 98 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.7 kB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 28.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 50.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 40.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "np.set_printoptions(precision=4)"
      ],
      "metadata": {
        "id": "AqzQM2pLOtGj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET"
      ],
      "metadata": {
        "id": "SLj3FM2UO7zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'dataset.csv'\n",
        "userid = pd.read_csv(dataset, sep=';', dtype={'User_id':str, 'Class_id':str})\n",
        "userid.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NxOwcMqtO3LW",
        "outputId": "c8d0f948-58a7-41c9-f540-ee89b5a2adb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  User_id Class_id  Order_Rating  Subject_id\n",
              "0      93       19           4.5           1\n",
              "1      32        3           2.3           3\n",
              "2      75       83           2.8           5\n",
              "3      18       12           4.9           1\n",
              "4      79       28           3.5           2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2778ab44-711c-422b-9d6e-fd19a1485c12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_id</th>\n",
              "      <th>Class_id</th>\n",
              "      <th>Order_Rating</th>\n",
              "      <th>Subject_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>93</td>\n",
              "      <td>19</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75</td>\n",
              "      <td>83</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>79</td>\n",
              "      <td>28</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2778ab44-711c-422b-9d6e-fd19a1485c12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2778ab44-711c-422b-9d6e-fd19a1485c12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2778ab44-711c-422b-9d6e-fd19a1485c12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kelas = 'kelas.csv'\n",
        "kelas = pd.read_csv(kelas, sep=';', dtype={'User_id':str, 'Class_id':str})\n",
        "kelas.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oEgDL-fRQY22",
        "outputId": "b01c68c8-3f15-42fe-a6d0-776c4285ab9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Class_id\n",
              "0       68\n",
              "1       27\n",
              "2       82\n",
              "3       90\n",
              "4       31"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aeec2afa-e42c-4628-900d-8bbe6ba39a36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeec2afa-e42c-4628-900d-8bbe6ba39a36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aeec2afa-e42c-4628-900d-8bbe6ba39a36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aeec2afa-e42c-4628-900d-8bbe6ba39a36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "userid = tf.data.Dataset.from_tensor_slices(dict(userid))\n",
        "\n",
        "for feature_batch in userid.take(1):\n",
        "  for key, value in feature_batch.items():\n",
        "    print(\"  {!r:20s}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIpyr8evQHbW",
        "outputId": "2e13096e-8b73-4ac3-c321-96f2ef23bff1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  'User_id'           : b'93'\n",
            "  'Class_id'          : b'19'\n",
            "  'Order_Rating'      : 4.5\n",
            "  'Subject_id'        : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kelas = tf.data.Dataset.from_tensor_slices(dict(kelas))\n",
        "\n",
        "for feature_batch in kelas.take(1):\n",
        "  for key, value in feature_batch.items():\n",
        "    print(\"  {!r:20s}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osSWivgLQSTC",
        "outputId": "d5deccc9-6b3b-4b27-eb9b-6c8aa9025163"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  'Class_id'          : b'68'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = userid.map(lambda x: {\n",
        "    \"Class_id\": x[\"Class_id\"],\n",
        "    \"User_id\": x[\"User_id\"],\n",
        "    \"Order_Rating\": x[\"Order_Rating\"],\n",
        "})\n",
        "class_id = kelas.map(lambda x: x[\"Class_id\"])"
      ],
      "metadata": {
        "id": "85E_X5sOR8Rp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating = np.concatenate(list(userid.map(lambda x: x[\"Order_Rating\"]).batch(100)))\n",
        "\n",
        "max_rating = rating.max()\n",
        "min_rating = rating.min()\n",
        "\n",
        "rating_buckets = np.linspace(\n",
        "    min_rating, max_rating, num=1000,\n",
        ")\n",
        "\n",
        "unique_class_ids = np.unique(np.concatenate(list(class_id.batch(1000))))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_id.batch(1_000).map(\n",
        "    lambda x: x[\"User_id\"]))))"
      ],
      "metadata": {
        "id": "puFaakCcSgTg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL"
      ],
      "metadata": {
        "id": "Z-vT6mGwPJ6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "query model"
      ],
      "metadata": {
        "id": "908IbjjVPgXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=unique_user_ids, mask_token=None),\n",
        "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "    ])\n",
        "    self.rating_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.Discretization(rating_buckets.tolist()),\n",
        "        tf.keras.layers.Embedding(len(rating_buckets) + 1, 32),\n",
        "    ])\n",
        "    self.normalized_rating = tf.keras.layers.Normalization(\n",
        "        axis=None\n",
        "    )\n",
        "\n",
        "    self.normalized_rating.adapt(rating)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Take the input dictionary, pass it through each input layer,\n",
        "    # and concatenate the result.\n",
        "    return tf.concat([\n",
        "        self.user_embedding(inputs[\"User_id\"]),\n",
        "        self.rating_embedding(inputs[\"Order_Rating\"]),\n",
        "        tf.reshape(self.normalized_rating(inputs[\"Order_Rating\"]), (-1, 1)),\n",
        "    ], axis=1)"
      ],
      "metadata": {
        "id": "BKzmJvpzPH0Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, layer_sizes):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    # We first use the user model for generating embeddings.\n",
        "    self.embedding_model = UserModel()\n",
        "\n",
        "    # Then construct the layers.\n",
        "    self.dense_layers = tf.keras.Sequential()\n",
        "\n",
        "    # Use the ReLU activation for all but the last layer.\n",
        "    for layer_size in layer_sizes[:-1]:\n",
        "      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
        "\n",
        "    # No activation for the last layer.\n",
        "    for layer_size in layer_sizes[-1:]:\n",
        "      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    feature_embedding = self.embedding_model(inputs)\n",
        "    return self.dense_layers(feature_embedding)"
      ],
      "metadata": {
        "id": "8ab6Y85ATgiA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "candidate Model"
      ],
      "metadata": {
        "id": "H19igOpETs6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class kelasModel(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.class_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "          vocabulary=unique_class_ids,mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_class_ids) + 1, 32)\n",
        "    ])\n",
        "\n",
        "    self.class_vectorizer = tf.keras.layers.TextVectorization(\n",
        "        max_tokens=max_tokens)\n",
        "\n",
        "    self.class_text_embedding = tf.keras.Sequential([\n",
        "      self.class_vectorizer,\n",
        "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "    self.class_vectorizer.adapt(class_id)\n",
        "\n",
        "  def call(self, titles):\n",
        "    return tf.concat([\n",
        "        self.class_embedding(titles),\n",
        "        self.class_text_embedding(titles),\n",
        "    ], axis=1)"
      ],
      "metadata": {
        "id": "DKMMzPGWToOQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CandidateModel(tf.keras.Model):\n",
        " \n",
        "  def __init__(self, layer_sizes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding_model = kelasModel()\n",
        "\n",
        "    self.dense_layers = tf.keras.Sequential()\n",
        "\n",
        "    for layer_size in layer_sizes[:-1]:\n",
        "      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
        "\n",
        "    for layer_size in layer_sizes[-1:]:\n",
        "      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    feature_embedding = self.embedding_model(inputs)\n",
        "    return self.dense_layers(feature_embedding)"
      ],
      "metadata": {
        "id": "Ydt3mR1LUHty"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "combined model"
      ],
      "metadata": {
        "id": "muwlI_BDUSgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MainModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, layer_sizes):\n",
        "    super().__init__()\n",
        "    self.query_model = QueryModel(layer_sizes)\n",
        "    self.candidate_model = CandidateModel(layer_sizes)\n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=class_id.batch(128).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "   \n",
        "    query_embeddings = self.query_model({\n",
        "        \"User_id\": features[\"User_id\"],\n",
        "        \"Order_Rating\": features[\"Order_Rating\"],\n",
        "    })\n",
        "    class_embeddings = self.candidate_model(features[\"Class_id\"])\n",
        "\n",
        "    return self.task(\n",
        "        query_embeddings, class_embeddings, compute_metrics=not training)"
      ],
      "metadata": {
        "id": "uHfMHiYWUPtl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "GHOTgzjCUt5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = user_id.shuffle(8000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(8000)\n",
        "test = shuffled.skip(2000).take(100)\n",
        "\n",
        "cached_train = train.shuffle(10000).batch(1024).cache()\n",
        "cached_test = test.batch(512).cache()"
      ],
      "metadata": {
        "id": "FvN8rdoIUmBz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MainModel([64, 32])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "model.fit(cached_train,epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psAF8th4kbjO",
        "outputId": "60e1c292-8c83-4530-e3d4-b370e4845d61"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6864.5471 - regularization_loss: 0.0000e+00 - total_loss: 6864.5471\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6766.7999 - regularization_loss: 0.0000e+00 - total_loss: 6766.7999\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6759.6858 - regularization_loss: 0.0000e+00 - total_loss: 6759.6858\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6751.7739 - regularization_loss: 0.0000e+00 - total_loss: 6751.7739\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6742.0014 - regularization_loss: 0.0000e+00 - total_loss: 6742.0014\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6728.7336 - regularization_loss: 0.0000e+00 - total_loss: 6728.7336\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6718.4250 - regularization_loss: 0.0000e+00 - total_loss: 6718.4250\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6694.8287 - regularization_loss: 0.0000e+00 - total_loss: 6694.8287\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6673.5493 - regularization_loss: 0.0000e+00 - total_loss: 6673.5493\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6655.7866 - regularization_loss: 0.0000e+00 - total_loss: 6655.7866\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6623.4341 - regularization_loss: 0.0000e+00 - total_loss: 6623.4341\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6591.8446 - regularization_loss: 0.0000e+00 - total_loss: 6591.8446\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6570.9237 - regularization_loss: 0.0000e+00 - total_loss: 6570.9237\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6533.4941 - regularization_loss: 0.0000e+00 - total_loss: 6533.4941\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6506.6339 - regularization_loss: 0.0000e+00 - total_loss: 6506.6339\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6491.0829 - regularization_loss: 0.0000e+00 - total_loss: 6491.0829\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6457.3817 - regularization_loss: 0.0000e+00 - total_loss: 6457.3817\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6426.6596 - regularization_loss: 0.0000e+00 - total_loss: 6426.6596\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6419.3130 - regularization_loss: 0.0000e+00 - total_loss: 6419.3130\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6381.6503 - regularization_loss: 0.0000e+00 - total_loss: 6381.6503\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6357.1479 - regularization_loss: 0.0000e+00 - total_loss: 6357.1479\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6341.8230 - regularization_loss: 0.0000e+00 - total_loss: 6341.8230\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6324.9870 - regularization_loss: 0.0000e+00 - total_loss: 6324.9870\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6304.3082 - regularization_loss: 0.0000e+00 - total_loss: 6304.3082\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6280.9635 - regularization_loss: 0.0000e+00 - total_loss: 6280.9635\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6266.1513 - regularization_loss: 0.0000e+00 - total_loss: 6266.1513\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6252.8692 - regularization_loss: 0.0000e+00 - total_loss: 6252.8692\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6238.4720 - regularization_loss: 0.0000e+00 - total_loss: 6238.4720\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6217.1108 - regularization_loss: 0.0000e+00 - total_loss: 6217.1108\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6201.1536 - regularization_loss: 0.0000e+00 - total_loss: 6201.1536\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6192.6001 - regularization_loss: 0.0000e+00 - total_loss: 6192.6001\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6178.9078 - regularization_loss: 0.0000e+00 - total_loss: 6178.9078\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6174.1348 - regularization_loss: 0.0000e+00 - total_loss: 6174.1348\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6154.6508 - regularization_loss: 0.0000e+00 - total_loss: 6154.6508\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6142.4983 - regularization_loss: 0.0000e+00 - total_loss: 6142.4983\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6132.4284 - regularization_loss: 0.0000e+00 - total_loss: 6132.4284\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6122.4502 - regularization_loss: 0.0000e+00 - total_loss: 6122.4502\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6115.7403 - regularization_loss: 0.0000e+00 - total_loss: 6115.7403\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6105.7688 - regularization_loss: 0.0000e+00 - total_loss: 6105.7688\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6097.5187 - regularization_loss: 0.0000e+00 - total_loss: 6097.5187\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6086.9595 - regularization_loss: 0.0000e+00 - total_loss: 6086.9595\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6078.5227 - regularization_loss: 0.0000e+00 - total_loss: 6078.5227\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6073.9526 - regularization_loss: 0.0000e+00 - total_loss: 6073.9526\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6066.4891 - regularization_loss: 0.0000e+00 - total_loss: 6066.4891\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6057.7624 - regularization_loss: 0.0000e+00 - total_loss: 6057.7624\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6050.7963 - regularization_loss: 0.0000e+00 - total_loss: 6050.7963\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6041.2250 - regularization_loss: 0.0000e+00 - total_loss: 6041.2250\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6039.4229 - regularization_loss: 0.0000e+00 - total_loss: 6039.4229\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6030.0204 - regularization_loss: 0.0000e+00 - total_loss: 6030.0204\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6023.3572 - regularization_loss: 0.0000e+00 - total_loss: 6023.3572\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6016.9996 - regularization_loss: 0.0000e+00 - total_loss: 6016.9996\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6011.7978 - regularization_loss: 0.0000e+00 - total_loss: 6011.7978\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6009.1509 - regularization_loss: 0.0000e+00 - total_loss: 6009.1509\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6001.0009 - regularization_loss: 0.0000e+00 - total_loss: 6001.0009\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5996.7546 - regularization_loss: 0.0000e+00 - total_loss: 5996.7546\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5991.7777 - regularization_loss: 0.0000e+00 - total_loss: 5991.7777\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5984.8813 - regularization_loss: 0.0000e+00 - total_loss: 5984.8813\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5982.0033 - regularization_loss: 0.0000e+00 - total_loss: 5982.0033\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5976.9484 - regularization_loss: 0.0000e+00 - total_loss: 5976.9484\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5971.8371 - regularization_loss: 0.0000e+00 - total_loss: 5971.8371\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5967.6801 - regularization_loss: 0.0000e+00 - total_loss: 5967.6801\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5962.6731 - regularization_loss: 0.0000e+00 - total_loss: 5962.6731\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5959.2725 - regularization_loss: 0.0000e+00 - total_loss: 5959.2725\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5955.8491 - regularization_loss: 0.0000e+00 - total_loss: 5955.8491\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5951.2444 - regularization_loss: 0.0000e+00 - total_loss: 5951.2444\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5946.2731 - regularization_loss: 0.0000e+00 - total_loss: 5946.2731\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5942.0507 - regularization_loss: 0.0000e+00 - total_loss: 5942.0507\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5938.4882 - regularization_loss: 0.0000e+00 - total_loss: 5938.4882\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5934.9671 - regularization_loss: 0.0000e+00 - total_loss: 5934.9671\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5930.2266 - regularization_loss: 0.0000e+00 - total_loss: 5930.2266\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5927.4634 - regularization_loss: 0.0000e+00 - total_loss: 5927.4634\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 27ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5923.1257 - regularization_loss: 0.0000e+00 - total_loss: 5923.1257\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5921.6342 - regularization_loss: 0.0000e+00 - total_loss: 5921.6342\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5917.1200 - regularization_loss: 0.0000e+00 - total_loss: 5917.1200\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5913.0614 - regularization_loss: 0.0000e+00 - total_loss: 5913.0614\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5910.8111 - regularization_loss: 0.0000e+00 - total_loss: 5910.8111\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5906.4198 - regularization_loss: 0.0000e+00 - total_loss: 5906.4198\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 33ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5904.3215 - regularization_loss: 0.0000e+00 - total_loss: 5904.3215\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5901.1091 - regularization_loss: 0.0000e+00 - total_loss: 5901.1091\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 43ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5898.3158 - regularization_loss: 0.0000e+00 - total_loss: 5898.3158\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 39ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5894.2456 - regularization_loss: 0.0000e+00 - total_loss: 5894.2456\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 38ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5891.7104 - regularization_loss: 0.0000e+00 - total_loss: 5891.7104\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 37ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5888.9576 - regularization_loss: 0.0000e+00 - total_loss: 5888.9576\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 38ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5885.7942 - regularization_loss: 0.0000e+00 - total_loss: 5885.7942\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 36ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5883.2289 - regularization_loss: 0.0000e+00 - total_loss: 5883.2289\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 40ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5880.9225 - regularization_loss: 0.0000e+00 - total_loss: 5880.9225\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5877.6593 - regularization_loss: 0.0000e+00 - total_loss: 5877.6593\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 43ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5874.0967 - regularization_loss: 0.0000e+00 - total_loss: 5874.0967\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5872.4708 - regularization_loss: 0.0000e+00 - total_loss: 5872.4708\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5869.6048 - regularization_loss: 0.0000e+00 - total_loss: 5869.6048\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 34ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5868.4534 - regularization_loss: 0.0000e+00 - total_loss: 5868.4534\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 32ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5864.5938 - regularization_loss: 0.0000e+00 - total_loss: 5864.5938\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5862.3394 - regularization_loss: 0.0000e+00 - total_loss: 5862.3394\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5860.0691 - regularization_loss: 0.0000e+00 - total_loss: 5860.0691\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5857.4651 - regularization_loss: 0.0000e+00 - total_loss: 5857.4651\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5854.6649 - regularization_loss: 0.0000e+00 - total_loss: 5854.6649\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 43ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5853.3415 - regularization_loss: 0.0000e+00 - total_loss: 5853.3415\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 40ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5851.1907 - regularization_loss: 0.0000e+00 - total_loss: 5851.1907\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 35ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5848.0551 - regularization_loss: 0.0000e+00 - total_loss: 5848.0551\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 38ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5846.5674 - regularization_loss: 0.0000e+00 - total_loss: 5846.5674\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 40ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5844.6503 - regularization_loss: 0.0000e+00 - total_loss: 5844.6503\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5842.3397 - regularization_loss: 0.0000e+00 - total_loss: 5842.3397\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 44ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5839.8597 - regularization_loss: 0.0000e+00 - total_loss: 5839.8597\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5837.5266 - regularization_loss: 0.0000e+00 - total_loss: 5837.5266\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 32ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5835.3389 - regularization_loss: 0.0000e+00 - total_loss: 5835.3389\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5833.6554 - regularization_loss: 0.0000e+00 - total_loss: 5833.6554\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5832.3034 - regularization_loss: 0.0000e+00 - total_loss: 5832.3034\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 40ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5830.4508 - regularization_loss: 0.0000e+00 - total_loss: 5830.4508\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5828.1769 - regularization_loss: 0.0000e+00 - total_loss: 5828.1769\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 42ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5825.9718 - regularization_loss: 0.0000e+00 - total_loss: 5825.9718\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 41ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5824.8496 - regularization_loss: 0.0000e+00 - total_loss: 5824.8496\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 59ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5822.7637 - regularization_loss: 0.0000e+00 - total_loss: 5822.7637\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 1s 64ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5821.0901 - regularization_loss: 0.0000e+00 - total_loss: 5821.0901\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5819.0279 - regularization_loss: 0.0000e+00 - total_loss: 5819.0279\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5817.9411 - regularization_loss: 0.0000e+00 - total_loss: 5817.9411\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 42ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5815.7298 - regularization_loss: 0.0000e+00 - total_loss: 5815.7298\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5814.1682 - regularization_loss: 0.0000e+00 - total_loss: 5814.1682\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5812.0809 - regularization_loss: 0.0000e+00 - total_loss: 5812.0809\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5811.1893 - regularization_loss: 0.0000e+00 - total_loss: 5811.1893\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5808.7198 - regularization_loss: 0.0000e+00 - total_loss: 5808.7198\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 39ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5807.9131 - regularization_loss: 0.0000e+00 - total_loss: 5807.9131\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 42ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5806.3106 - regularization_loss: 0.0000e+00 - total_loss: 5806.3106\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5804.8114 - regularization_loss: 0.0000e+00 - total_loss: 5804.8114\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 42ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5801.9956 - regularization_loss: 0.0000e+00 - total_loss: 5801.9956\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5800.6335 - regularization_loss: 0.0000e+00 - total_loss: 5800.6335\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 43ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5799.1672 - regularization_loss: 0.0000e+00 - total_loss: 5799.1672\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5797.7358 - regularization_loss: 0.0000e+00 - total_loss: 5797.7358\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5796.3296 - regularization_loss: 0.0000e+00 - total_loss: 5796.3296\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5794.0375 - regularization_loss: 0.0000e+00 - total_loss: 5794.0375\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5792.8359 - regularization_loss: 0.0000e+00 - total_loss: 5792.8359\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5791.3497 - regularization_loss: 0.0000e+00 - total_loss: 5791.3497\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5789.6419 - regularization_loss: 0.0000e+00 - total_loss: 5789.6419\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5789.4081 - regularization_loss: 0.0000e+00 - total_loss: 5789.4081\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5786.6946 - regularization_loss: 0.0000e+00 - total_loss: 5786.6946\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5785.0803 - regularization_loss: 0.0000e+00 - total_loss: 5785.0803\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5783.3210 - regularization_loss: 0.0000e+00 - total_loss: 5783.3210\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 33ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5781.7290 - regularization_loss: 0.0000e+00 - total_loss: 5781.7290\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5780.7172 - regularization_loss: 0.0000e+00 - total_loss: 5780.7172\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5779.2216 - regularization_loss: 0.0000e+00 - total_loss: 5779.2216\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5778.5723 - regularization_loss: 0.0000e+00 - total_loss: 5778.5723\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5776.2973 - regularization_loss: 0.0000e+00 - total_loss: 5776.2973\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5775.3548 - regularization_loss: 0.0000e+00 - total_loss: 5775.3548\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5774.8621 - regularization_loss: 0.0000e+00 - total_loss: 5774.8621\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5771.8686 - regularization_loss: 0.0000e+00 - total_loss: 5771.8686\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5771.9008 - regularization_loss: 0.0000e+00 - total_loss: 5771.9008\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5771.1861 - regularization_loss: 0.0000e+00 - total_loss: 5771.1861\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5769.0600 - regularization_loss: 0.0000e+00 - total_loss: 5769.0600\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5767.9724 - regularization_loss: 0.0000e+00 - total_loss: 5767.9724\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5766.0493 - regularization_loss: 0.0000e+00 - total_loss: 5766.0493\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5766.1743 - regularization_loss: 0.0000e+00 - total_loss: 5766.1743\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5764.0435 - regularization_loss: 0.0000e+00 - total_loss: 5764.0435\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5762.8415 - regularization_loss: 0.0000e+00 - total_loss: 5762.8415\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5761.7609 - regularization_loss: 0.0000e+00 - total_loss: 5761.7609\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 28ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5760.4594 - regularization_loss: 0.0000e+00 - total_loss: 5760.4594\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5759.1902 - regularization_loss: 0.0000e+00 - total_loss: 5759.1902\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 36ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5758.6960 - regularization_loss: 0.0000e+00 - total_loss: 5758.6960\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5757.4096 - regularization_loss: 0.0000e+00 - total_loss: 5757.4096\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 36ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5755.5560 - regularization_loss: 0.0000e+00 - total_loss: 5755.5560\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 40ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5754.3706 - regularization_loss: 0.0000e+00 - total_loss: 5754.3706\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 38ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5753.8939 - regularization_loss: 0.0000e+00 - total_loss: 5753.8939\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 38ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5752.8052 - regularization_loss: 0.0000e+00 - total_loss: 5752.8052\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 42ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5751.5633 - regularization_loss: 0.0000e+00 - total_loss: 5751.5633\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5749.9017 - regularization_loss: 0.0000e+00 - total_loss: 5749.9017\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 45ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5749.2597 - regularization_loss: 0.0000e+00 - total_loss: 5749.2597\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 41ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5747.7509 - regularization_loss: 0.0000e+00 - total_loss: 5747.7509\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5747.5768 - regularization_loss: 0.0000e+00 - total_loss: 5747.5768\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5746.0539 - regularization_loss: 0.0000e+00 - total_loss: 5746.0539\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5744.4503 - regularization_loss: 0.0000e+00 - total_loss: 5744.4503\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5743.3494 - regularization_loss: 0.0000e+00 - total_loss: 5743.3494\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 36ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5742.6745 - regularization_loss: 0.0000e+00 - total_loss: 5742.6745\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 47ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5741.5532 - regularization_loss: 0.0000e+00 - total_loss: 5741.5532\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5741.5833 - regularization_loss: 0.0000e+00 - total_loss: 5741.5833\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5739.5208 - regularization_loss: 0.0000e+00 - total_loss: 5739.5208\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5738.4040 - regularization_loss: 0.0000e+00 - total_loss: 5738.4040\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 1s 67ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5738.2215 - regularization_loss: 0.0000e+00 - total_loss: 5738.2215\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 1s 64ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5736.9017 - regularization_loss: 0.0000e+00 - total_loss: 5736.9017\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 63ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5735.9626 - regularization_loss: 0.0000e+00 - total_loss: 5735.9626\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 1s 63ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5734.8703 - regularization_loss: 0.0000e+00 - total_loss: 5734.8703\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5734.3390 - regularization_loss: 0.0000e+00 - total_loss: 5734.3390\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 1s 64ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5733.2661 - regularization_loss: 0.0000e+00 - total_loss: 5733.2661\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5732.7822 - regularization_loss: 0.0000e+00 - total_loss: 5732.7822\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5731.6157 - regularization_loss: 0.0000e+00 - total_loss: 5731.6157\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 1s 65ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5730.0527 - regularization_loss: 0.0000e+00 - total_loss: 5730.0527\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 1s 69ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5729.4742 - regularization_loss: 0.0000e+00 - total_loss: 5729.4742\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5729.1501 - regularization_loss: 0.0000e+00 - total_loss: 5729.1501\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 1s 64ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5727.8291 - regularization_loss: 0.0000e+00 - total_loss: 5727.8291\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 1s 69ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5726.9894 - regularization_loss: 0.0000e+00 - total_loss: 5726.9894\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 1s 74ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5726.2533 - regularization_loss: 0.0000e+00 - total_loss: 5726.2533\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5724.9620 - regularization_loss: 0.0000e+00 - total_loss: 5724.9620\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5723.7922 - regularization_loss: 0.0000e+00 - total_loss: 5723.7922\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5723.2026 - regularization_loss: 0.0000e+00 - total_loss: 5723.2026\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5722.0901 - regularization_loss: 0.0000e+00 - total_loss: 5722.0901\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5721.4461 - regularization_loss: 0.0000e+00 - total_loss: 5721.4461\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5720.1839 - regularization_loss: 0.0000e+00 - total_loss: 5720.1839\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5719.7558 - regularization_loss: 0.0000e+00 - total_loss: 5719.7558\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5718.3668 - regularization_loss: 0.0000e+00 - total_loss: 5718.3668\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5717.5591 - regularization_loss: 0.0000e+00 - total_loss: 5717.5591\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5717.3030 - regularization_loss: 0.0000e+00 - total_loss: 5717.3030\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5716.4485 - regularization_loss: 0.0000e+00 - total_loss: 5716.4485\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 5715.8700 - regularization_loss: 0.0000e+00 - total_loss: 5715.8700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f497dec0ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval = tfrs.layers.factorized_top_k.ScaNN(model.query_model, k= 3, num_leaves = 10)\n",
        "\n",
        "retrieval.index_from_dataset(\n",
        "  tf.data.Dataset.zip((class_id.batch(1000), class_id.batch(1000).map(model.candidate_model)))\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTWZXz7xVbWR",
        "outputId": "6178fc15-cdea-40b0-f9ec-3754d3afcdae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7f497db2f790>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(retrieval, \"/content/sample_data/Model\", options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"]))"
      ],
      "metadata": {
        "id": "2I9SmihklqbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419bd443-cda0-4d7e-9d11-b0677a8cb42a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.layers.factorized_top_k.ScaNN object at 0x7f497db2f790>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/sample_data/Model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/sample_data/Model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QzlJsx_RRNKX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}