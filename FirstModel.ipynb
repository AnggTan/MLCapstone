{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDsxMVtlqkQK",
        "outputId": "13246a81-6aeb-45b0-b969-9f00ed9fc9ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 934 kB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 2.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow_recommenders\n",
        "!pip install -q ScaNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "dfcymi_NqnH4",
        "outputId": "bbc8e1d7-c173-4451-c7fb-78e10fd9fdf1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-97d1d7c6-f734-483e-b658-8438f7cf8ea6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-97d1d7c6-f734-483e-b658-8438f7cf8ea6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving rec_data.csv to rec_data.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rec_data.csv': b'User_Id,Class_Id,Order_Rating\\r\\n228,1,4\\r\\n263,28,4\\r\\n310,4,4\\r\\n72,27,1\\r\\n238,25,5\\r\\n183,28,5\\r\\n269,39,4\\r\\n271,28,2\\r\\n62,41,4\\r\\n346,45,1\\r\\n352,8,5\\r\\n250,38,3\\r\\n100,42,2\\r\\n234,36,3\\r\\n185,29,2\\r\\n21,2,1\\r\\n284,21,1\\r\\n71,47,3\\r\\n239,32,1\\r\\n6,48,2\\r\\n86,2,1\\r\\n117,12,2\\r\\n50,4,2\\r\\n198,14,5\\r\\n215,46,1\\r\\n186,32,2\\r\\n47,8,2\\r\\n113,42,1\\r\\n25,16,4\\r\\n317,9,1\\r\\n70,2,3\\r\\n323,10,1\\r\\n78,39,4\\r\\n198,23,4\\r\\n142,5,4\\r\\n148,19,3\\r\\n351,8,1\\r\\n243,29,3\\r\\n150,2,5\\r\\n27,17,3\\r\\n229,13,2\\r\\n81,19,5\\r\\n257,40,5\\r\\n127,30,5\\r\\n284,49,4\\r\\n342,45,5\\r\\n220,28,2\\r\\n330,38,3\\r\\n136,37,2\\r\\n112,26,4\\r\\n163,28,2\\r\\n222,40,5\\r\\n238,37,2\\r\\n88,44,5\\r\\n239,10,1\\r\\n233,7,4\\r\\n177,10,5\\r\\n165,11,4\\r\\n38,21,4\\r\\n312,40,4\\r\\n74,43,5\\r\\n142,13,3\\r\\n231,38,4\\r\\n263,34,3\\r\\n46,7,1\\r\\n6,35,5\\r\\n90,45,4\\r\\n78,16,3\\r\\n62,15,2\\r\\n99,36,5\\r\\n324,5,1\\r\\n326,38,5\\r\\n106,35,3\\r\\n301,32,5\\r\\n268,2,2\\r\\n25,38,1\\r\\n209,25,4\\r\\n81,46,5\\r\\n344,19,4\\r\\n286,21,3\\r\\n5,13,5\\r\\n124,13,5\\r\\n241,31,2\\r\\n203,45,4\\r\\n135,45,5\\r\\n4,5,3\\r\\n17,16,3\\r\\n4,26,1\\r\\n338,37,5\\r\\n50,29,1\\r\\n332,36,3\\r\\n260,26,4\\r\\n265,41,5\\r\\n179,45,3\\r\\n174,5,4\\r\\n283,28,3\\r\\n179,20,3\\r\\n251,33,4\\r\\n348,16,5\\r\\n136,6,1\\r\\n129,31,3\\r\\n248,4,2\\r\\n35,2,2\\r\\n240,28,1\\r\\n284,46,4\\r\\n199,28,3\\r\\n11,7,4\\r\\n103,21,4\\r\\n128,34,4\\r\\n159,12,4\\r\\n259,25,3\\r\\n211,27,4\\r\\n131,48,4\\r\\n41,10,5\\r\\n159,45,1\\r\\n79,5,5\\r\\n271,44,1\\r\\n262,40,3\\r\\n198,35,3\\r\\n298,29,2\\r\\n140,34,2\\r\\n223,16,5\\r\\n69,13,2\\r\\n155,37,5\\r\\n65,10,1\\r\\n37,29,4\\r\\n170,28,5\\r\\n215,34,3\\r\\n170,35,1\\r\\n262,2,3\\r\\n139,46,4\\r\\n99,43,4\\r\\n329,46,3\\r\\n122,44,3\\r\\n141,29,4\\r\\n187,8,5\\r\\n314,47,4\\r\\n108,22,4\\r\\n51,47,4\\r\\n251,41,3\\r\\n95,12,4\\r\\n164,49,5\\r\\n185,36,1\\r\\n214,45,5\\r\\n165,37,4\\r\\n71,18,2\\r\\n227,25,3\\r\\n276,36,2\\r\\n300,50,2\\r\\n300,3,4\\r\\n84,40,5\\r\\n270,22,1\\r\\n90,9,5\\r\\n210,39,1\\r\\n347,29,4\\r\\n104,29,1\\r\\n60,28,4\\r\\n96,33,5\\r\\n338,35,3\\r\\n351,19,4\\r\\n54,32,3\\r\\n26,37,1\\r\\n173,46,2\\r\\n314,43,5\\r\\n178,15,3\\r\\n150,29,4\\r\\n194,44,4\\r\\n70,3,5\\r\\n148,8,2\\r\\n23,21,5\\r\\n75,34,1\\r\\n337,7,5\\r\\n217,12,4\\r\\n300,49,2\\r\\n353,25,1\\r\\n319,44,5\\r\\n62,38,4\\r\\n26,18,4\\r\\n300,13,5\\r\\n306,48,3\\r\\n188,9,3\\r\\n56,35,3\\r\\n22,44,1\\r\\n294,24,5\\r\\n59,45,4\\r\\n282,44,2\\r\\n119,16,2\\r\\n254,11,3\\r\\n162,6,2\\r\\n144,29,4\\r\\n300,18,4\\r\\n128,7,2\\r\\n96,3,1\\r\\n102,40,3\\r\\n235,33,3\\r\\n115,26,4\\r\\n38,44,4\\r\\n266,16,5\\r\\n300,27,4\\r\\n282,21,4\\r\\n282,5,4\\r\\n169,30,5\\r\\n193,15,2\\r\\n162,39,2\\r\\n304,30,1\\r\\n130,19,3\\r\\n206,33,4\\r\\n152,5,5\\r\\n87,28,1\\r\\n274,11,5\\r\\n337,5,2\\r\\n340,31,5\\r\\n61,38,2\\r\\n154,14,5\\r\\n255,35,4\\r\\n323,5,5\\r\\n120,15,2\\r\\n185,2,2\\r\\n170,34,2\\r\\n188,32,1\\r\\n119,31,5\\r\\n132,12,2\\r\\n121,13,5\\r\\n291,38,1\\r\\n164,34,3\\r\\n302,12,1\\r\\n113,14,3\\r\\n272,34,2\\r\\n323,15,5\\r\\n277,22,5\\r\\n53,16,5\\r\\n84,31,2\\r\\n4,49,5\\r\\n22,10,4\\r\\n225,14,3\\r\\n123,17,1\\r\\n148,34,2\\r\\n280,48,2\\r\\n46,39,3\\r\\n336,9,4\\r\\n336,20,4\\r\\n42,30,5\\r\\n188,15,5\\r\\n307,48,2\\r\\n32,30,4\\r\\n140,35,5\\r\\n196,7,2\\r\\n32,32,4\\r\\n244,49,2\\r\\n201,23,4\\r\\n26,3,4\\r\\n105,3,1\\r\\n160,16,4\\r\\n145,30,4\\r\\n46,12,4\\r\\n311,21,3\\r\\n101,47,1\\r\\n116,8,3\\r\\n194,47,5\\r\\n26,1,2\\r\\n256,31,5\\r\\n3,11,3\\r\\n101,7,5\\r\\n313,25,1\\r\\n122,35,1\\r\\n27,3,5\\r\\n226,23,3\\r\\n30,26,2\\r\\n278,1,5\\r\\n132,4,5\\r\\n271,18,2\\r\\n157,29,4\\r\\n293,22,4\\r\\n337,45,2\\r\\n233,16,3\\r\\n50,47,3\\r\\n257,5,3\\r\\n206,37,4\\r\\n256,35,1\\r\\n316,33,2\\r\\n185,3,5\\r\\n141,3,2\\r\\n6,31,3\\r\\n70,5,2\\r\\n205,34,4\\r\\n321,44,4\\r\\n66,23,2\\r\\n137,31,2\\r\\n282,14,4\\r\\n75,40,2\\r\\n225,16,3\\r\\n131,26,4\\r\\n127,6,5\\r\\n24,26,3\\r\\n215,46,5\\r\\n188,28,5\\r\\n122,26,2\\r\\n320,5,3\\r\\n38,39,2\\r\\n305,49,5\\r\\n135,50,4\\r\\n107,5,2\\r\\n27,39,3\\r\\n341,36,3\\r\\n51,45,1\\r\\n134,6,2\\r\\n164,6,3\\r\\n66,8,3\\r\\n275,37,1\\r\\n315,6,2\\r\\n296,3,3\\r\\n23,5,5\\r\\n180,24,3\\r\\n245,17,5\\r\\n158,5,2\\r\\n242,37,3\\r\\n242,43,5\\r\\n127,20,2\\r\\n296,31,5\\r\\n169,24,3\\r\\n302,41,3\\r\\n62,10,4\\r\\n227,31,5\\r\\n162,34,4\\r\\n280,29,3\\r\\n104,31,3\\r\\n281,11,4\\r\\n305,16,1\\r\\n118,31,2\\r\\n249,23,3\\r\\n132,49,1\\r\\n319,30,3\\r\\n44,24,1\\r\\n15,47,4\\r\\n267,1,2\\r\\n294,44,2\\r\\n315,25,4\\r\\n40,16,3\\r\\n299,22,1\\r\\n93,6,1\\r\\n131,22,2\\r\\n292,21,2\\r\\n130,33,3\\r\\n85,29,4\\r\\n136,34,1\\r\\n145,43,3\\r\\n63,50,3\\r\\n1,14,1\\r\\n224,22,2\\r\\n174,36,4\\r\\n312,21,3\\r\\n64,5,5\\r\\n161,38,4\\r\\n299,45,2\\r\\n213,32,1\\r\\n12,32,1\\r\\n38,28,3\\r\\n60,7,2\\r\\n273,15,2\\r\\n217,31,2\\r\\n140,45,3\\r\\n130,41,1\\r\\n350,12,1\\r\\n132,29,5\\r\\n313,19,1\\r\\n326,19,3\\r\\n85,42,1\\r\\n315,2,2\\r\\n68,16,5\\r\\n139,43,4\\r\\n166,10,4\\r\\n42,44,3\\r\\n285,5,5\\r\\n116,28,3\\r\\n73,6,2\\r\\n50,50,2\\r\\n57,35,1\\r\\n128,14,4\\r\\n26,26,4\\r\\n27,38,5\\r\\n298,50,3\\r\\n290,34,1\\r\\n149,46,3\\r\\n210,34,1\\r\\n169,28,4\\r\\n135,8,2\\r\\n38,26,1\\r\\n75,23,2\\r\\n112,45,4\\r\\n51,17,3\\r\\n309,43,4\\r\\n262,38,3\\r\\n271,26,1\\r\\n46,4,1\\r\\n18,44,2\\r\\n2,37,1\\r\\n60,21,4\\r\\n175,6,4\\r\\n232,14,2\\r\\n188,43,4\\r\\n168,22,4\\r\\n254,25,5\\r\\n310,21,3\\r\\n53,3,4\\r\\n47,35,4\\r\\n37,3,3\\r\\n289,1,5\\r\\n235,19,5\\r\\n20,27,5\\r\\n189,48,1\\r\\n57,29,5\\r\\n116,7,3\\r\\n190,25,4\\r\\n30,9,4\\r\\n162,14,2\\r\\n148,1,2\\r\\n98,33,5\\r\\n14,41,4\\r\\n329,29,2\\r\\n324,16,4\\r\\n271,18,3\\r\\n56,14,5\\r\\n60,33,1\\r\\n288,49,1\\r\\n321,27,4\\r\\n212,9,2\\r\\n155,30,2\\r\\n91,27,3\\r\\n298,23,3\\r\\n234,46,5\\r\\n303,50,2\\r\\n248,17,3\\r\\n251,20,3\\r\\n327,41,3\\r\\n192,38,2\\r\\n352,45,4\\r\\n34,20,4\\r\\n297,14,2\\r\\n243,36,5\\r\\n43,27,5\\r\\n320,49,1\\r\\n312,21,2\\r\\n210,36,4\\r\\n210,37,1\\r\\n204,47,5\\r\\n217,48,2\\r\\n234,23,1\\r\\n314,5,1\\r\\n268,37,1\\r\\n219,22,2\\r\\n273,35,5\\r\\n300,8,3\\r\\n67,32,1\\r\\n243,24,3\\r\\n157,12,1\\r\\n175,6,4\\r\\n34,29,2\\r\\n85,24,3\\r\\n117,47,1\\r\\n291,23,4\\r\\n117,47,4\\r\\n74,42,4\\r\\n316,7,1\\r\\n147,35,5\\r\\n293,24,1\\r\\n111,44,2\\r\\n340,39,4\\r\\n84,31,2\\r\\n243,4,2\\r\\n24,12,5\\r\\n314,4,1\\r\\n230,15,1\\r\\n70,26,1\\r\\n58,31,5\\r\\n28,39,5\\r\\n260,23,4\\r\\n33,23,4\\r\\n145,3,5\\r\\n228,4,5\\r\\n21,25,4\\r\\n87,42,4\\r\\n199,34,5\\r\\n195,31,4\\r\\n327,42,4\\r\\n354,38,4\\r\\n330,7,5\\r\\n223,30,1\\r\\n167,35,3\\r\\n315,46,2\\r\\n52,40,1\\r\\n7,6,4\\r\\n207,17,4\\r\\n278,10,4\\r\\n125,3,5\\r\\n236,25,2\\r\\n97,14,3\\r\\n108,15,3\\r\\n323,15,4\\r\\n254,20,2\\r\\n122,47,2\\r\\n148,15,3\\r\\n208,20,4\\r\\n154,50,1\\r\\n317,17,1\\r\\n158,49,1\\r\\n226,49,3\\r\\n174,43,4\\r\\n202,1,1\\r\\n345,33,1\\r\\n218,28,3\\r\\n221,13,4\\r\\n104,34,2\\r\\n296,24,3\\r\\n78,33,1\\r\\n274,12,1\\r\\n302,28,1\\r\\n7,44,3\\r\\n14,4,2\\r\\n98,37,5\\r\\n114,8,3\\r\\n103,45,1\\r\\n146,27,4\\r\\n227,20,1\\r\\n299,17,3\\r\\n229,2,4\\r\\n176,3,2\\r\\n199,1,2\\r\\n15,2,1\\r\\n285,15,5\\r\\n8,13,3\\r\\n282,2,4\\r\\n171,25,4\\r\\n24,37,4\\r\\n192,11,3\\r\\n8,2,4\\r\\n220,16,5\\r\\n245,3,3\\r\\n14,6,4\\r\\n158,27,4\\r\\n201,17,2\\r\\n242,34,2\\r\\n82,45,2\\r\\n197,23,5\\r\\n109,6,4\\r\\n170,11,2\\r\\n111,46,2\\r\\n19,50,3\\r\\n122,15,3\\r\\n143,2,2\\r\\n202,27,3\\r\\n340,20,3\\r\\n150,7,2\\r\\n137,15,4\\r\\n238,13,5\\r\\n196,18,5\\r\\n149,36,1\\r\\n281,8,2\\r\\n127,27,1\\r\\n27,19,3\\r\\n284,7,1\\r\\n281,34,4\\r\\n95,8,3\\r\\n292,12,1\\r\\n292,24,4\\r\\n255,49,3\\r\\n191,20,4\\r\\n263,5,4\\r\\n294,21,4\\r\\n211,29,4\\r\\n34,33,3\\r\\n187,38,3\\r\\n137,14,4\\r\\n6,33,3\\r\\n29,23,5\\r\\n6,6,2\\r\\n281,28,5\\r\\n337,35,4\\r\\n35,26,2\\r\\n327,32,2\\r\\n108,28,2\\r\\n82,8,4\\r\\n337,35,1\\r\\n151,29,5\\r\\n331,18,3\\r\\n307,9,2\\r\\n66,37,4\\r\\n322,49,5\\r\\n86,45,2\\r\\n183,6,3\\r\\n131,10,4\\r\\n226,12,4\\r\\n347,14,4\\r\\n352,5,4\\r\\n21,47,2\\r\\n258,33,3\\r\\n63,19,5\\r\\n110,27,2\\r\\n117,49,3\\r\\n303,30,1\\r\\n210,27,1\\r\\n247,6,2\\r\\n290,21,5\\r\\n204,22,4\\r\\n323,26,1\\r\\n12,49,1\\r\\n277,44,3\\r\\n242,8,4\\r\\n263,31,3\\r\\n17,36,1\\r\\n103,13,4\\r\\n132,27,2\\r\\n53,23,3\\r\\n290,10,4\\r\\n45,9,4\\r\\n6,18,3\\r\\n328,41,4\\r\\n349,19,2\\r\\n100,33,5\\r\\n109,12,2\\r\\n257,22,1\\r\\n230,29,3\\r\\n112,42,1\\r\\n346,23,1\\r\\n144,14,1\\r\\n325,22,3\\r\\n260,36,4\\r\\n102,24,5\\r\\n323,16,2\\r\\n211,46,1\\r\\n61,26,5\\r\\n292,43,2\\r\\n179,31,4\\r\\n221,46,2\\r\\n299,22,2\\r\\n314,24,3\\r\\n149,15,1\\r\\n297,26,5\\r\\n145,30,4\\r\\n333,30,2\\r\\n146,6,3\\r\\n125,41,2\\r\\n108,22,2\\r\\n76,7,5\\r\\n342,37,2\\r\\n94,49,5\\r\\n43,26,5\\r\\n223,16,3\\r\\n276,11,2\\r\\n344,44,2\\r\\n125,10,4\\r\\n158,40,4\\r\\n92,36,2\\r\\n166,1,2\\r\\n257,45,4\\r\\n291,1,5\\r\\n127,42,4\\r\\n317,21,1\\r\\n52,9,3\\r\\n162,2,4\\r\\n6,7,5\\r\\n159,31,5\\r\\n111,29,5\\r\\n314,16,4\\r\\n284,46,5\\r\\n324,9,3\\r\\n326,2,3\\r\\n60,42,5\\r\\n226,46,2\\r\\n52,19,1\\r\\n2,46,5\\r\\n317,6,5\\r\\n76,24,2\\r\\n353,3,1\\r\\n29,50,1\\r\\n86,33,4\\r\\n250,7,5\\r\\n143,10,4\\r\\n142,41,1\\r\\n105,3,4\\r\\n322,28,1\\r\\n139,34,2\\r\\n79,29,2\\r\\n50,31,4\\r\\n268,15,3\\r\\n252,21,4\\r\\n229,14,5\\r\\n134,21,4\\r\\n103,46,4\\r\\n50,2,3\\r\\n186,27,2\\r\\n56,4,2\\r\\n74,45,4\\r\\n22,32,4\\r\\n289,7,2\\r\\n84,26,2\\r\\n204,10,4\\r\\n210,50,5\\r\\n108,42,3\\r\\n28,27,5\\r\\n269,29,3\\r\\n104,22,1\\r\\n268,41,2\\r\\n239,12,2\\r\\n103,46,2\\r\\n58,34,1\\r\\n33,15,3\\r\\n139,1,3\\r\\n71,45,2\\r\\n350,15,5\\r\\n66,6,3\\r\\n320,8,5\\r\\n140,34,5\\r\\n71,12,2\\r\\n274,43,1\\r\\n228,17,3\\r\\n82,22,1\\r\\n164,4,5\\r\\n309,44,1\\r\\n11,41,5\\r\\n106,19,3\\r\\n24,5,5\\r\\n175,41,2\\r\\n330,9,3\\r\\n212,18,2\\r\\n190,46,4\\r\\n189,47,4\\r\\n294,23,5\\r\\n300,32,3\\r\\n105,34,4\\r\\n192,48,5\\r\\n266,9,5\\r\\n59,35,1\\r\\n222,42,1\\r\\n175,26,5\\r\\n127,30,5\\r\\n294,44,3\\r\\n155,28,4\\r\\n107,3,5\\r\\n222,9,4\\r\\n31,36,4\\r\\n64,46,1\\r\\n216,11,2\\r\\n278,22,1\\r\\n345,17,2\\r\\n38,16,3\\r\\n33,23,5\\r\\n45,11,1\\r\\n166,35,3\\r\\n279,41,1\\r\\n116,26,1\\r\\n21,4,4\\r\\n10,37,1\\r\\n164,33,2\\r\\n274,2,5\\r\\n273,29,5\\r\\n118,9,5\\r\\n10,19,4\\r\\n62,19,4\\r\\n256,10,4\\r\\n135,7,4\\r\\n118,14,5\\r\\n282,38,1\\r\\n189,25,5\\r\\n197,19,5\\r\\n39,45,2\\r\\n8,41,4\\r\\n137,3,5\\r\\n26,38,4\\r\\n106,17,5\\r\\n309,19,4\\r\\n240,8,4\\r\\n350,13,2\\r\\n207,8,3\\r\\n350,43,3\\r\\n12,12,1\\r\\n60,15,3\\r\\n172,45,2\\r\\n3,44,4\\r\\n3,19,3\\r\\n289,33,2\\r\\n234,48,2\\r\\n143,32,2\\r\\n172,4,4\\r\\n106,16,2\\r\\n348,45,5\\r\\n31,46,4\\r\\n153,24,3\\r\\n222,23,5\\r\\n111,15,3\\r\\n209,20,4\\r\\n158,48,2\\r\\n43,32,4\\r\\n308,26,2\\r\\n67,22,4\\r\\n150,1,4\\r\\n302,4,2\\r\\n8,32,3\\r\\n78,34,2\\r\\n306,3,3\\r\\n256,15,4\\r\\n316,4,4\\r\\n200,36,5\\r\\n158,45,4\\r\\n243,30,1\\r\\n175,49,1\\r\\n221,20,3\\r\\n2,22,5\\r\\n29,34,1\\r\\n350,15,1\\r\\n189,22,1\\r\\n308,18,2\\r\\n267,40,2\\r\\n267,5,4\\r\\n83,3,1\\r\\n334,7,1\\r\\n44,31,1\\r\\n297,8,5\\r\\n102,18,5\\r\\n74,44,5\\r\\n134,41,3\\r\\n273,6,4\\r\\n179,45,5\\r\\n273,39,5\\r\\n258,23,2\\r\\n316,16,3\\r\\n246,7,1\\r\\n250,14,4\\r\\n70,18,4\\r\\n174,32,1\\r\\n24,14,3\\r\\n30,18,2\\r\\n229,35,5\\r\\n345,32,3\\r\\n156,13,2\\r\\n281,34,1\\r\\n127,17,1\\r\\n260,35,2\\r\\n271,6,2\\r\\n11,10,4\\r\\n141,24,3\\r\\n264,12,3\\r\\n221,38,2\\r\\n121,29,3\\r\\n242,9,1\\r\\n94,2,2\\r\\n292,41,5\\r\\n165,37,2\\r\\n120,27,3\\r\\n290,26,3\\r\\n337,16,1\\r\\n255,37,5\\r\\n189,42,5\\r\\n196,45,2\\r\\n311,30,4\\r\\n46,32,5\\r\\n31,25,5\\r\\n219,20,3\\r\\n107,3,4\\r\\n244,35,2\\r\\n257,5,1\\r\\n69,26,1\\r\\n258,48,2\\r\\n72,15,4\\r\\n340,26,2\\r\\n165,4,2\\r\\n142,9,4\\r\\n125,50,2\\r\\n187,8,4\\r\\n171,34,1\\r\\n236,28,1\\r\\n195,34,4\\r\\n311,25,4\\r\\n12,15,2\\r\\n182,37,5\\r\\n211,48,4\\r\\n55,9,1\\r\\n344,17,2\\r\\n134,31,3\\r\\n139,46,2\\r\\n21,42,1\\r\\n338,46,1\\r\\n129,12,1\\r\\n322,26,3\\r\\n53,17,4\\r\\n163,1,5\\r\\n310,13,3\\r\\n47,47,3\\r\\n22,32,1\\r\\n289,29,2\\r\\n28,43,3\\r\\n161,31,5\\r\\n345,21,1\\r\\n246,38,1\\r\\n3,1,1\\r\\n73,11,5\\r\\n286,6,5\\r\\n240,16,2\\r\\n107,37,4\\r\\n6,4,1\\r\\n54,47,2\\r\\n16,9,3\\r\\n142,29,1\\r\\n339,4,4\\r\\n18,22,2\\r\\n125,15,2\\r\\n109,33,3\\r\\n282,33,2\\r\\n321,44,1\\r\\n162,39,3\\r\\n276,49,5\\r\\n329,40,3\\r\\n134,9,3\\r\\n246,20,4\\r\\n24,1,2\\r\\n13,6,1\\r\\n247,18,4\\r\\n221,41,4\\r\\n143,47,5\\r\\n250,15,4\\r\\n180,2,2\\r\\n264,34,3\\r\\n153,13,2\\r\\n19,42,2\\r\\n16,25,2\\r\\n222,34,1\\r\\n52,44,4\\r\\n172,17,5\\r\\n221,46,2\\r\\n249,45,3\\r\\n69,20,5\\r\\n267,40,4\\r\\n204,41,5\\r\\n14,1,2\\r\\n46,14,4\\r\\n75,31,3\\r\\n194,17,3\\r\\n57,8,2\\r\\n47,38,2\\r\\n280,3,5\\r\\n2,15,5\\r\\n296,3,3\\r\\n151,34,3\\r\\n47,13,2\\r\\n33,3,5\\r\\n71,16,4\\r\\n117,3,5\\r\\n139,10,1\\r\\n166,15,1\\r\\n222,16,5\\r\\n158,5,4\\r\\n12,24,2\\r\\n74,35,3\\r\\n122,22,1\\r\\n32,6,4\\r\\n156,7,5\\r\\n172,41,4\\r\\n145,25,5\\r\\n314,31,5\\r\\n344,10,4\\r\\n257,7,3\\r\\n288,16,4\\r\\n36,45,4\\r\\n71,33,5\\r\\n118,4,2\\r\\n121,33,3\\r\\n352,15,5\\r\\n143,7,2\\r\\n66,46,5\\r\\n189,29,4\\r\\n317,40,4\\r\\n111,38,1\\r\\n60,20,2\\r\\n187,39,4\\r\\n274,32,4\\r\\n246,24,4\\r\\n85,50,4\\r\\n18,46,5\\r\\n293,43,2\\r\\n279,29,3\\r\\n232,18,1\\r\\n175,41,2\\r\\n158,11,2\\r\\n166,4,3\\r\\n129,14,4\\r\\n48,20,3\\r\\n126,36,4\\r\\n126,49,5\\r\\n78,6,4\\r\\n353,1,4\\r\\n206,38,5\\r\\n304,35,4\\r\\n285,38,4\\r\\n215,25,1\\r\\n134,15,5\\r\\n310,5,3\\r\\n34,24,4\\r\\n143,22,3\\r\\n122,3,4\\r\\n160,16,3\\r\\n248,46,1\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ETgtLqE0rMW6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv(\"/content/rec_data.csv\")\n",
        "dataframe[[\"User_Id\", \"Class_Id\"]] = dataframe[[\"User_Id\", \"Class_Id\"]].astype(str)\n",
        "dataframe[[\"Order_Rating\"]] = dataframe[[\"Order_Rating\"]].astype(float)\n",
        "dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9oiAY2gRqzgX",
        "outputId": "d3cc4de6-1fc1-4df5-a205-582a9bb8432b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    User_Id Class_Id  Order_Rating\n",
              "0       228        1           4.0\n",
              "1       263       28           4.0\n",
              "2       310        4           4.0\n",
              "3        72       27           1.0\n",
              "4       238       25           5.0\n",
              "..      ...      ...           ...\n",
              "995      34       24           4.0\n",
              "996     143       22           3.0\n",
              "997     122        3           4.0\n",
              "998     160       16           3.0\n",
              "999     248       46           1.0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0da77af9-d295-4eb9-ac4e-ce1a468758bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Id</th>\n",
              "      <th>Class_Id</th>\n",
              "      <th>Order_Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>228</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263</td>\n",
              "      <td>28</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>310</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>72</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>238</td>\n",
              "      <td>25</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>34</td>\n",
              "      <td>24</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>143</td>\n",
              "      <td>22</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>122</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>160</td>\n",
              "      <td>16</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>248</td>\n",
              "      <td>46</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0da77af9-d295-4eb9-ac4e-ce1a468758bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0da77af9-d295-4eb9-ac4e-ce1a468758bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0da77af9-d295-4eb9-ac4e-ce1a468758bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inter_dict = dataframe.groupby([\"User_Id\", \"Class_Id\"])[\"Order_Rating\"].agg(np.mean).reset_index()\n",
        "print(inter_dict)\n",
        "inter_dict = {name: np.array(value) for name, value in inter_dict.items()}\n",
        "interaction = tf.data.Dataset.from_tensor_slices(inter_dict)\n",
        "\n",
        "prod_dict = dataframe[[\"Class_Id\"]].drop_duplicates()\n",
        "prod_dict = {name: np.array(value) for name, value in prod_dict.items()}\n",
        "product = tf.data.Dataset.from_tensor_slices(prod_dict)\n",
        "\n",
        "interaction = interaction.map(lambda x: {\n",
        "    \"User_Id\": x[\"User_Id\"],\n",
        "    \"Class_Id\": x[\"Class_Id\"],\n",
        "    \"Order_Rating\": float(x[\"Order_Rating\"])\n",
        "})\n",
        "product = product.map(lambda x: x[\"Class_Id\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shrjKZfirllJ",
        "outputId": "a45d9bc1-81c5-4bab-f2e5-4fa14f19fdeb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    User_Id Class_Id  Order_Rating\n",
            "0         1       14           1.0\n",
            "1        10       19           4.0\n",
            "2        10       37           1.0\n",
            "3       100       33           5.0\n",
            "4       100       42           2.0\n",
            "..      ...      ...           ...\n",
            "959      97       14           3.0\n",
            "960      98       33           5.0\n",
            "961      98       37           5.0\n",
            "962      99       36           5.0\n",
            "963      99       43           4.0\n",
            "\n",
            "[964 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = interaction.batch(100).map(lambda x: x[\"User_Id\"])\n",
        "product_ids = interaction.batch(100).map(lambda x: x[\"Class_Id\"])\n",
        "\n",
        "unique_user = np.unique(np.concatenate(list(user_ids)))\n",
        "unique_product = np.unique(np.concatenate(list(product_ids)))\n",
        "print(unique_user)\n",
        "print(unique_product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JwE57PktmNG",
        "outputId": "6d9424f1-3cba-4400-afc4-5e7cfe5c1961"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'1' b'10' b'100' b'101' b'102' b'103' b'104' b'105' b'106' b'107' b'108'\n",
            " b'109' b'11' b'110' b'111' b'112' b'113' b'114' b'115' b'116' b'117'\n",
            " b'118' b'119' b'12' b'120' b'121' b'122' b'123' b'124' b'125' b'126'\n",
            " b'127' b'128' b'129' b'13' b'130' b'131' b'132' b'134' b'135' b'136'\n",
            " b'137' b'139' b'14' b'140' b'141' b'142' b'143' b'144' b'145' b'146'\n",
            " b'147' b'148' b'149' b'15' b'150' b'151' b'152' b'153' b'154' b'155'\n",
            " b'156' b'157' b'158' b'159' b'16' b'160' b'161' b'162' b'163' b'164'\n",
            " b'165' b'166' b'167' b'168' b'169' b'17' b'170' b'171' b'172' b'173'\n",
            " b'174' b'175' b'176' b'177' b'178' b'179' b'18' b'180' b'182' b'183'\n",
            " b'185' b'186' b'187' b'188' b'189' b'19' b'190' b'191' b'192' b'193'\n",
            " b'194' b'195' b'196' b'197' b'198' b'199' b'2' b'20' b'200' b'201' b'202'\n",
            " b'203' b'204' b'205' b'206' b'207' b'208' b'209' b'21' b'210' b'211'\n",
            " b'212' b'213' b'214' b'215' b'216' b'217' b'218' b'219' b'22' b'220'\n",
            " b'221' b'222' b'223' b'224' b'225' b'226' b'227' b'228' b'229' b'23'\n",
            " b'230' b'231' b'232' b'233' b'234' b'235' b'236' b'238' b'239' b'24'\n",
            " b'240' b'241' b'242' b'243' b'244' b'245' b'246' b'247' b'248' b'249'\n",
            " b'25' b'250' b'251' b'252' b'254' b'255' b'256' b'257' b'258' b'259'\n",
            " b'26' b'260' b'262' b'263' b'264' b'265' b'266' b'267' b'268' b'269'\n",
            " b'27' b'270' b'271' b'272' b'273' b'274' b'275' b'276' b'277' b'278'\n",
            " b'279' b'28' b'280' b'281' b'282' b'283' b'284' b'285' b'286' b'288'\n",
            " b'289' b'29' b'290' b'291' b'292' b'293' b'294' b'296' b'297' b'298'\n",
            " b'299' b'3' b'30' b'300' b'301' b'302' b'303' b'304' b'305' b'306' b'307'\n",
            " b'308' b'309' b'31' b'310' b'311' b'312' b'313' b'314' b'315' b'316'\n",
            " b'317' b'319' b'32' b'320' b'321' b'322' b'323' b'324' b'325' b'326'\n",
            " b'327' b'328' b'329' b'33' b'330' b'331' b'332' b'333' b'334' b'336'\n",
            " b'337' b'338' b'339' b'34' b'340' b'341' b'342' b'344' b'345' b'346'\n",
            " b'347' b'348' b'349' b'35' b'350' b'351' b'352' b'353' b'354' b'36' b'37'\n",
            " b'38' b'39' b'4' b'40' b'41' b'42' b'43' b'44' b'45' b'46' b'47' b'48'\n",
            " b'5' b'50' b'51' b'52' b'53' b'54' b'55' b'56' b'57' b'58' b'59' b'6'\n",
            " b'60' b'61' b'62' b'63' b'64' b'65' b'66' b'67' b'68' b'69' b'7' b'70'\n",
            " b'71' b'72' b'73' b'74' b'75' b'76' b'78' b'79' b'8' b'81' b'82' b'83'\n",
            " b'84' b'85' b'86' b'87' b'88' b'90' b'91' b'92' b'93' b'94' b'95' b'96'\n",
            " b'97' b'98' b'99']\n",
            "[b'1' b'10' b'11' b'12' b'13' b'14' b'15' b'16' b'17' b'18' b'19' b'2'\n",
            " b'20' b'21' b'22' b'23' b'24' b'25' b'26' b'27' b'28' b'29' b'3' b'30'\n",
            " b'31' b'32' b'33' b'34' b'35' b'36' b'37' b'38' b'39' b'4' b'40' b'41'\n",
            " b'42' b'43' b'44' b'45' b'46' b'47' b'48' b'49' b'5' b'50' b'6' b'7' b'8'\n",
            " b'9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = interaction.shuffle(100, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(800)\n",
        "test = shuffled.skip(800).take(164)\n",
        "\n",
        "cached_train = train.shuffle(100).batch(128)\n",
        "cached_test = test.batch(256).cache()"
      ],
      "metadata": {
        "id": "3RcNlX0Xv9Zz"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(tfrs.models.Model):\n",
        "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    embed_dim = 32\n",
        "\n",
        "    self.product_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "          tf.keras.layers.StringLookup(vocabulary = unique_product, mask_token = None),\n",
        "          tf.keras.layers.Embedding(len(unique_product) + 1, embed_dim)\n",
        "    ])\n",
        "\n",
        "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "          tf.keras.layers.StringLookup(vocabulary = unique_user, mask_token = None),\n",
        "          tf.keras.layers.Embedding(len(unique_user) + 1, embed_dim)\n",
        "    ])\n",
        "\n",
        "    self.rating_model = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "          tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "          tf.keras.layers.Dense(1),\n",
        "        ])\n",
        "    \n",
        "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "          metrics = tfrs.metrics.FactorizedTopK(\n",
        "            candidates = product.batch(128).map(self.product_model)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "          loss = tf.keras.losses.MeanSquaredError(),\n",
        "          metrics = [tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "    self.retrieval_weight = retrieval_weight\n",
        "    self.rating_weight = rating_weight\n",
        "\n",
        "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "    user_embeddings = self.user_model(features[\"User_Id\"])\n",
        "    product_embeddings = self.product_model(features[\"Class_Id\"])\n",
        "    return(\n",
        "        user_embeddings, product_embeddings, self.rating_model(tf.concat([user_embeddings, product_embeddings], axis = 1),)\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training = False) -> tf.Tensor:\n",
        "    ratings = features.pop(\"Order_Rating\")\n",
        "    user_embeddings, product_embeddings, rating_predictions = self(features)\n",
        "\n",
        "    retrieval_loss = self.retrieval_task(user_embeddings, product_embeddings)\n",
        "    rating_loss = self.rating_task(\n",
        "        labels = ratings,\n",
        "        predictions = rating_predictions\n",
        "    )\n",
        "    return (self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss)"
      ],
      "metadata": {
        "id": "PtHDHBylwvHr"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(rating_weight=1, retrieval_weight=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "YRioJI-jxTwR"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=50)\n",
        "metrics = model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"top 5 accuracy: {metrics['factorized_top_k/top_5_categorical_accuracy']:.3f}.\")\n",
        "print(f\"RMSE Ranking: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXrVLTmbxX3y",
        "outputId": "5e4d6dbf-a9b1-4982-8b2c-402961167840"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 2s 62ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0650 - factorized_top_k/top_10_categorical_accuracy: 0.1675 - factorized_top_k/top_50_categorical_accuracy: 0.9862 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 2.3928 - loss: 498.4463 - regularization_loss: 0.0000e+00 - total_loss: 498.4463\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 63ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.4250 - factorized_top_k/top_10_categorical_accuracy: 0.7312 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3953 - loss: 492.5746 - regularization_loss: 0.0000e+00 - total_loss: 492.5746\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6413 - factorized_top_k/top_10_categorical_accuracy: 0.8913 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3708 - loss: 478.9183 - regularization_loss: 0.0000e+00 - total_loss: 478.9183\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.7250 - factorized_top_k/top_10_categorical_accuracy: 0.9350 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.5347 - loss: 441.7412 - regularization_loss: 0.0000e+00 - total_loss: 441.7412\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.8050 - factorized_top_k/top_10_categorical_accuracy: 0.9688 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3439 - loss: 388.0447 - regularization_loss: 0.0000e+00 - total_loss: 388.0447\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0125 - factorized_top_k/top_5_categorical_accuracy: 0.8400 - factorized_top_k/top_10_categorical_accuracy: 0.9862 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3817 - loss: 340.5625 - regularization_loss: 0.0000e+00 - total_loss: 340.5625\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 48ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0150 - factorized_top_k/top_5_categorical_accuracy: 0.8712 - factorized_top_k/top_10_categorical_accuracy: 0.9975 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.4185 - loss: 309.1552 - regularization_loss: 0.0000e+00 - total_loss: 309.1552\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0300 - factorized_top_k/top_5_categorical_accuracy: 0.8825 - factorized_top_k/top_10_categorical_accuracy: 0.9987 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3455 - loss: 286.8005 - regularization_loss: 0.0000e+00 - total_loss: 286.8005\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0538 - factorized_top_k/top_5_categorical_accuracy: 0.8963 - factorized_top_k/top_10_categorical_accuracy: 0.9987 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3082 - loss: 274.7433 - regularization_loss: 0.0000e+00 - total_loss: 274.7433\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0650 - factorized_top_k/top_5_categorical_accuracy: 0.8950 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2664 - loss: 264.9607 - regularization_loss: 0.0000e+00 - total_loss: 264.9607\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 62ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0725 - factorized_top_k/top_5_categorical_accuracy: 0.8988 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2674 - loss: 260.6286 - regularization_loss: 0.0000e+00 - total_loss: 260.6286\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 62ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0800 - factorized_top_k/top_5_categorical_accuracy: 0.9050 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2264 - loss: 253.9411 - regularization_loss: 0.0000e+00 - total_loss: 253.9411\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0913 - factorized_top_k/top_5_categorical_accuracy: 0.9038 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2167 - loss: 251.9228 - regularization_loss: 0.0000e+00 - total_loss: 251.9228\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1112 - factorized_top_k/top_5_categorical_accuracy: 0.9087 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2207 - loss: 248.1224 - regularization_loss: 0.0000e+00 - total_loss: 248.1224\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1025 - factorized_top_k/top_5_categorical_accuracy: 0.9038 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2035 - loss: 248.2497 - regularization_loss: 0.0000e+00 - total_loss: 248.2497\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1287 - factorized_top_k/top_5_categorical_accuracy: 0.9075 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.1950 - loss: 247.3506 - regularization_loss: 0.0000e+00 - total_loss: 247.3506\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1138 - factorized_top_k/top_5_categorical_accuracy: 0.9212 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.1514 - loss: 246.7494 - regularization_loss: 0.0000e+00 - total_loss: 246.7494\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1250 - factorized_top_k/top_5_categorical_accuracy: 0.9087 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.1569 - loss: 243.7413 - regularization_loss: 0.0000e+00 - total_loss: 243.7413\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 60ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1175 - factorized_top_k/top_5_categorical_accuracy: 0.9125 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.0535 - loss: 242.4524 - regularization_loss: 0.0000e+00 - total_loss: 242.4524\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1163 - factorized_top_k/top_5_categorical_accuracy: 0.9100 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.0299 - loss: 240.0216 - regularization_loss: 0.0000e+00 - total_loss: 240.0216\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1000 - factorized_top_k/top_5_categorical_accuracy: 0.9125 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.1375 - loss: 238.3342 - regularization_loss: 0.0000e+00 - total_loss: 238.3342\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0975 - factorized_top_k/top_5_categorical_accuracy: 0.9150 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.9962 - loss: 238.9857 - regularization_loss: 0.0000e+00 - total_loss: 238.9857\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1287 - factorized_top_k/top_5_categorical_accuracy: 0.9112 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.9136 - loss: 239.8749 - regularization_loss: 0.0000e+00 - total_loss: 239.8749\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1187 - factorized_top_k/top_5_categorical_accuracy: 0.9137 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.7952 - loss: 238.4958 - regularization_loss: 0.0000e+00 - total_loss: 238.4958\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1112 - factorized_top_k/top_5_categorical_accuracy: 0.9100 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.7589 - loss: 236.9585 - regularization_loss: 0.0000e+00 - total_loss: 236.9585\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1100 - factorized_top_k/top_5_categorical_accuracy: 0.9212 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.0842 - loss: 237.3342 - regularization_loss: 0.0000e+00 - total_loss: 237.3342\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 64ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1187 - factorized_top_k/top_5_categorical_accuracy: 0.9137 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.7725 - loss: 235.7561 - regularization_loss: 0.0000e+00 - total_loss: 235.7561\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 49ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1075 - factorized_top_k/top_5_categorical_accuracy: 0.9212 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.9638 - loss: 235.3805 - regularization_loss: 0.0000e+00 - total_loss: 235.3805\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1200 - factorized_top_k/top_5_categorical_accuracy: 0.9137 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.7652 - loss: 234.8150 - regularization_loss: 0.0000e+00 - total_loss: 234.8150\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1138 - factorized_top_k/top_5_categorical_accuracy: 0.9137 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.7922 - loss: 237.8431 - regularization_loss: 0.0000e+00 - total_loss: 237.8431\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1163 - factorized_top_k/top_5_categorical_accuracy: 0.9150 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.6728 - loss: 233.1896 - regularization_loss: 0.0000e+00 - total_loss: 233.1896\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 50ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1125 - factorized_top_k/top_5_categorical_accuracy: 0.9162 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.8169 - loss: 234.5706 - regularization_loss: 0.0000e+00 - total_loss: 234.5706\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1238 - factorized_top_k/top_5_categorical_accuracy: 0.9187 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.5893 - loss: 233.4957 - regularization_loss: 0.0000e+00 - total_loss: 233.4957\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1312 - factorized_top_k/top_5_categorical_accuracy: 0.9200 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.5755 - loss: 234.4553 - regularization_loss: 0.0000e+00 - total_loss: 234.4553\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1175 - factorized_top_k/top_5_categorical_accuracy: 0.9237 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.5483 - loss: 235.4132 - regularization_loss: 0.0000e+00 - total_loss: 235.4132\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1287 - factorized_top_k/top_5_categorical_accuracy: 0.9187 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.6039 - loss: 233.9218 - regularization_loss: 0.0000e+00 - total_loss: 233.9218\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1312 - factorized_top_k/top_5_categorical_accuracy: 0.9212 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.4817 - loss: 235.0235 - regularization_loss: 0.0000e+00 - total_loss: 235.0235\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 64ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1175 - factorized_top_k/top_5_categorical_accuracy: 0.9212 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.4652 - loss: 233.3049 - regularization_loss: 0.0000e+00 - total_loss: 233.3049\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 59ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1200 - factorized_top_k/top_5_categorical_accuracy: 0.9262 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.6655 - loss: 232.8582 - regularization_loss: 0.0000e+00 - total_loss: 232.8582\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 64ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1175 - factorized_top_k/top_5_categorical_accuracy: 0.9225 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.4729 - loss: 233.6174 - regularization_loss: 0.0000e+00 - total_loss: 233.6174\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 62ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1238 - factorized_top_k/top_5_categorical_accuracy: 0.9250 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.4059 - loss: 234.0889 - regularization_loss: 0.0000e+00 - total_loss: 234.0889\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1163 - factorized_top_k/top_5_categorical_accuracy: 0.9137 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3995 - loss: 232.1998 - regularization_loss: 0.0000e+00 - total_loss: 232.1998\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1138 - factorized_top_k/top_5_categorical_accuracy: 0.9250 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3283 - loss: 232.1772 - regularization_loss: 0.0000e+00 - total_loss: 232.1772\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1275 - factorized_top_k/top_5_categorical_accuracy: 0.9162 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3347 - loss: 231.6338 - regularization_loss: 0.0000e+00 - total_loss: 231.6338\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1475 - factorized_top_k/top_5_categorical_accuracy: 0.9175 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3340 - loss: 230.8172 - regularization_loss: 0.0000e+00 - total_loss: 230.8172\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 62ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1063 - factorized_top_k/top_5_categorical_accuracy: 0.9162 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3518 - loss: 232.0732 - regularization_loss: 0.0000e+00 - total_loss: 232.0732\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1175 - factorized_top_k/top_5_categorical_accuracy: 0.9212 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.2873 - loss: 230.2593 - regularization_loss: 0.0000e+00 - total_loss: 230.2593\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1262 - factorized_top_k/top_5_categorical_accuracy: 0.9212 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3304 - loss: 231.3879 - regularization_loss: 0.0000e+00 - total_loss: 231.3879\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1112 - factorized_top_k/top_5_categorical_accuracy: 0.9225 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.2660 - loss: 230.1275 - regularization_loss: 0.0000e+00 - total_loss: 230.1275\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1200 - factorized_top_k/top_5_categorical_accuracy: 0.9225 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3424 - loss: 231.6735 - regularization_loss: 0.0000e+00 - total_loss: 231.6735\n",
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7945a139e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7945a139e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 551ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0061 - factorized_top_k/top_5_categorical_accuracy: 0.0610 - factorized_top_k/top_10_categorical_accuracy: 0.1890 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.6796 - loss: 1129.4384 - regularization_loss: 0.0000e+00 - total_loss: 1129.4384\n",
            "top 5 accuracy: 0.061.\n",
            "RMSE Ranking: 1.680.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval = tfrs.layers.factorized_top_k.ScaNN(model.user_model, k= 3, num_leaves = 10)\n",
        "retrieval.index_from_dataset(\n",
        "    tf.data.Dataset.zip((product.batch(5), product.batch(5).map(model.product_model))))\n",
        "_ = retrieval(np.array([\"29\"]))\n",
        "tf.saved_model.save(retrieval, \"/content/sample_data/Model\", options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC7i57qfxqXH",
        "outputId": "fe0fdf48-a055-4162-cb82-58d7249cc098"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/sample_data/Model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/sample_data/Model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load = tf.saved_model.load(\"/content/sample_data/Model\")"
      ],
      "metadata": {
        "id": "M6l2y3P_zLnV"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating, suggestion = load(np.array([\"110\"]))\n",
        "print(rating)\n",
        "print(suggestion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ5Vm4K73x2G",
        "outputId": "759ea552-a34b-4e6b-cc2b-48274b25af82"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[8.050923  3.828683  3.6267118]], shape=(1, 3), dtype=float32)\n",
            "tf.Tensor([[b'27' b'39' b'32']], shape=(1, 3), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "76Z9RgBv3_k6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}