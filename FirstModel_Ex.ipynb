{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDsxMVtlqkQK",
        "outputId": "bbca5c83-9bfa-4b92-b60d-cdf5525bb618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 4.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#install tensorflow recommenders\n",
        "!pip install -q tensorflow_recommenders\n",
        "!pip install -q ScaNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload dataset\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "dfcymi_NqnH4",
        "outputId": "f07bc2ec-20ae-48b4-f649-75880234d417"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f6c63610-83fa-40a7-bf30-e43ffce49597\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f6c63610-83fa-40a7-bf30-e43ffce49597\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving rec_data.csv to rec_data.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rec_data.csv': b'User_Id,Class_Id,Order_Rating\\r\\n228,1,4\\r\\n263,28,4\\r\\n310,4,4\\r\\n72,27,1\\r\\n238,25,5\\r\\n183,28,5\\r\\n269,39,4\\r\\n271,28,2\\r\\n62,41,4\\r\\n346,45,1\\r\\n352,8,5\\r\\n250,38,3\\r\\n100,42,2\\r\\n234,36,3\\r\\n185,29,2\\r\\n21,2,1\\r\\n284,21,1\\r\\n71,47,3\\r\\n239,32,1\\r\\n6,48,2\\r\\n86,2,1\\r\\n117,12,2\\r\\n50,4,2\\r\\n198,14,5\\r\\n215,46,1\\r\\n186,32,2\\r\\n47,8,2\\r\\n113,42,1\\r\\n25,16,4\\r\\n317,9,1\\r\\n70,2,3\\r\\n323,10,1\\r\\n78,39,4\\r\\n198,23,4\\r\\n142,5,4\\r\\n148,19,3\\r\\n351,8,1\\r\\n243,29,3\\r\\n150,2,5\\r\\n27,17,3\\r\\n229,13,2\\r\\n81,19,5\\r\\n257,40,5\\r\\n127,30,5\\r\\n284,49,4\\r\\n342,45,5\\r\\n220,28,2\\r\\n330,38,3\\r\\n136,37,2\\r\\n112,26,4\\r\\n163,28,2\\r\\n222,40,5\\r\\n238,37,2\\r\\n88,44,5\\r\\n239,10,1\\r\\n233,7,4\\r\\n177,10,5\\r\\n165,11,4\\r\\n38,21,4\\r\\n312,40,4\\r\\n74,43,5\\r\\n142,13,3\\r\\n231,38,4\\r\\n263,34,3\\r\\n46,7,1\\r\\n6,35,5\\r\\n90,45,4\\r\\n78,16,3\\r\\n62,15,2\\r\\n99,36,5\\r\\n324,5,1\\r\\n326,38,5\\r\\n106,35,3\\r\\n301,32,5\\r\\n268,2,2\\r\\n25,38,1\\r\\n209,25,4\\r\\n81,46,5\\r\\n344,19,4\\r\\n286,21,3\\r\\n5,13,5\\r\\n124,13,5\\r\\n241,31,2\\r\\n203,45,4\\r\\n135,45,5\\r\\n4,5,3\\r\\n17,16,3\\r\\n4,26,1\\r\\n338,37,5\\r\\n50,29,1\\r\\n332,36,3\\r\\n260,26,4\\r\\n265,41,5\\r\\n179,45,3\\r\\n174,5,4\\r\\n283,28,3\\r\\n179,20,3\\r\\n251,33,4\\r\\n348,16,5\\r\\n136,6,1\\r\\n129,31,3\\r\\n248,4,2\\r\\n35,2,2\\r\\n240,28,1\\r\\n284,46,4\\r\\n199,28,3\\r\\n11,7,4\\r\\n103,21,4\\r\\n128,34,4\\r\\n159,12,4\\r\\n259,25,3\\r\\n211,27,4\\r\\n131,48,4\\r\\n41,10,5\\r\\n159,45,1\\r\\n79,5,5\\r\\n271,44,1\\r\\n262,40,3\\r\\n198,35,3\\r\\n298,29,2\\r\\n140,34,2\\r\\n223,16,5\\r\\n69,13,2\\r\\n155,37,5\\r\\n65,10,1\\r\\n37,29,4\\r\\n170,28,5\\r\\n215,34,3\\r\\n170,35,1\\r\\n262,2,3\\r\\n139,46,4\\r\\n99,43,4\\r\\n329,46,3\\r\\n122,44,3\\r\\n141,29,4\\r\\n187,8,5\\r\\n314,47,4\\r\\n108,22,4\\r\\n51,47,4\\r\\n251,41,3\\r\\n95,12,4\\r\\n164,49,5\\r\\n185,36,1\\r\\n214,45,5\\r\\n165,37,4\\r\\n71,18,2\\r\\n227,25,3\\r\\n276,36,2\\r\\n300,50,2\\r\\n300,3,4\\r\\n84,40,5\\r\\n270,22,1\\r\\n90,9,5\\r\\n210,39,1\\r\\n347,29,4\\r\\n104,29,1\\r\\n60,28,4\\r\\n96,33,5\\r\\n338,35,3\\r\\n351,19,4\\r\\n54,32,3\\r\\n26,37,1\\r\\n173,46,2\\r\\n314,43,5\\r\\n178,15,3\\r\\n150,29,4\\r\\n194,44,4\\r\\n70,3,5\\r\\n148,8,2\\r\\n23,21,5\\r\\n75,34,1\\r\\n337,7,5\\r\\n217,12,4\\r\\n300,49,2\\r\\n353,25,1\\r\\n319,44,5\\r\\n62,38,4\\r\\n26,18,4\\r\\n300,13,5\\r\\n306,48,3\\r\\n188,9,3\\r\\n56,35,3\\r\\n22,44,1\\r\\n294,24,5\\r\\n59,45,4\\r\\n282,44,2\\r\\n119,16,2\\r\\n254,11,3\\r\\n162,6,2\\r\\n144,29,4\\r\\n300,18,4\\r\\n128,7,2\\r\\n96,3,1\\r\\n102,40,3\\r\\n235,33,3\\r\\n115,26,4\\r\\n38,44,4\\r\\n266,16,5\\r\\n300,27,4\\r\\n282,21,4\\r\\n282,5,4\\r\\n169,30,5\\r\\n193,15,2\\r\\n162,39,2\\r\\n304,30,1\\r\\n130,19,3\\r\\n206,33,4\\r\\n152,5,5\\r\\n87,28,1\\r\\n274,11,5\\r\\n337,5,2\\r\\n340,31,5\\r\\n61,38,2\\r\\n154,14,5\\r\\n255,35,4\\r\\n323,5,5\\r\\n120,15,2\\r\\n185,2,2\\r\\n170,34,2\\r\\n188,32,1\\r\\n119,31,5\\r\\n132,12,2\\r\\n121,13,5\\r\\n291,38,1\\r\\n164,34,3\\r\\n302,12,1\\r\\n113,14,3\\r\\n272,34,2\\r\\n323,15,5\\r\\n277,22,5\\r\\n53,16,5\\r\\n84,31,2\\r\\n4,49,5\\r\\n22,10,4\\r\\n225,14,3\\r\\n123,17,1\\r\\n148,34,2\\r\\n280,48,2\\r\\n46,39,3\\r\\n336,9,4\\r\\n336,20,4\\r\\n42,30,5\\r\\n188,15,5\\r\\n307,48,2\\r\\n32,30,4\\r\\n140,35,5\\r\\n196,7,2\\r\\n32,32,4\\r\\n244,49,2\\r\\n201,23,4\\r\\n26,3,4\\r\\n105,3,1\\r\\n160,16,4\\r\\n145,30,4\\r\\n46,12,4\\r\\n311,21,3\\r\\n101,47,1\\r\\n116,8,3\\r\\n194,47,5\\r\\n26,1,2\\r\\n256,31,5\\r\\n3,11,3\\r\\n101,7,5\\r\\n313,25,1\\r\\n122,35,1\\r\\n27,3,5\\r\\n226,23,3\\r\\n30,26,2\\r\\n278,1,5\\r\\n132,4,5\\r\\n271,18,2\\r\\n157,29,4\\r\\n293,22,4\\r\\n337,45,2\\r\\n233,16,3\\r\\n50,47,3\\r\\n257,5,3\\r\\n206,37,4\\r\\n256,35,1\\r\\n316,33,2\\r\\n185,3,5\\r\\n141,3,2\\r\\n6,31,3\\r\\n70,5,2\\r\\n205,34,4\\r\\n321,44,4\\r\\n66,23,2\\r\\n137,31,2\\r\\n282,14,4\\r\\n75,40,2\\r\\n225,16,3\\r\\n131,26,4\\r\\n127,6,5\\r\\n24,26,3\\r\\n215,46,5\\r\\n188,28,5\\r\\n122,26,2\\r\\n320,5,3\\r\\n38,39,2\\r\\n305,49,5\\r\\n135,50,4\\r\\n107,5,2\\r\\n27,39,3\\r\\n341,36,3\\r\\n51,45,1\\r\\n134,6,2\\r\\n164,6,3\\r\\n66,8,3\\r\\n275,37,1\\r\\n315,6,2\\r\\n296,3,3\\r\\n23,5,5\\r\\n180,24,3\\r\\n245,17,5\\r\\n158,5,2\\r\\n242,37,3\\r\\n242,43,5\\r\\n127,20,2\\r\\n296,31,5\\r\\n169,24,3\\r\\n302,41,3\\r\\n62,10,4\\r\\n227,31,5\\r\\n162,34,4\\r\\n280,29,3\\r\\n104,31,3\\r\\n281,11,4\\r\\n305,16,1\\r\\n118,31,2\\r\\n249,23,3\\r\\n132,49,1\\r\\n319,30,3\\r\\n44,24,1\\r\\n15,47,4\\r\\n267,1,2\\r\\n294,44,2\\r\\n315,25,4\\r\\n40,16,3\\r\\n299,22,1\\r\\n93,6,1\\r\\n131,22,2\\r\\n292,21,2\\r\\n130,33,3\\r\\n85,29,4\\r\\n136,34,1\\r\\n145,43,3\\r\\n63,50,3\\r\\n1,14,1\\r\\n224,22,2\\r\\n174,36,4\\r\\n312,21,3\\r\\n64,5,5\\r\\n161,38,4\\r\\n299,45,2\\r\\n213,32,1\\r\\n12,32,1\\r\\n38,28,3\\r\\n60,7,2\\r\\n273,15,2\\r\\n217,31,2\\r\\n140,45,3\\r\\n130,41,1\\r\\n350,12,1\\r\\n132,29,5\\r\\n313,19,1\\r\\n326,19,3\\r\\n85,42,1\\r\\n315,2,2\\r\\n68,16,5\\r\\n139,43,4\\r\\n166,10,4\\r\\n42,44,3\\r\\n285,5,5\\r\\n116,28,3\\r\\n73,6,2\\r\\n50,50,2\\r\\n57,35,1\\r\\n128,14,4\\r\\n26,26,4\\r\\n27,38,5\\r\\n298,50,3\\r\\n290,34,1\\r\\n149,46,3\\r\\n210,34,1\\r\\n169,28,4\\r\\n135,8,2\\r\\n38,26,1\\r\\n75,23,2\\r\\n112,45,4\\r\\n51,17,3\\r\\n309,43,4\\r\\n262,38,3\\r\\n271,26,1\\r\\n46,4,1\\r\\n18,44,2\\r\\n2,37,1\\r\\n60,21,4\\r\\n175,6,4\\r\\n232,14,2\\r\\n188,43,4\\r\\n168,22,4\\r\\n254,25,5\\r\\n310,21,3\\r\\n53,3,4\\r\\n47,35,4\\r\\n37,3,3\\r\\n289,1,5\\r\\n235,19,5\\r\\n20,27,5\\r\\n189,48,1\\r\\n57,29,5\\r\\n116,7,3\\r\\n190,25,4\\r\\n30,9,4\\r\\n162,14,2\\r\\n148,1,2\\r\\n98,33,5\\r\\n14,41,4\\r\\n329,29,2\\r\\n324,16,4\\r\\n271,18,3\\r\\n56,14,5\\r\\n60,33,1\\r\\n288,49,1\\r\\n321,27,4\\r\\n212,9,2\\r\\n155,30,2\\r\\n91,27,3\\r\\n298,23,3\\r\\n234,46,5\\r\\n303,50,2\\r\\n248,17,3\\r\\n251,20,3\\r\\n327,41,3\\r\\n192,38,2\\r\\n352,45,4\\r\\n34,20,4\\r\\n297,14,2\\r\\n243,36,5\\r\\n43,27,5\\r\\n320,49,1\\r\\n312,21,2\\r\\n210,36,4\\r\\n210,37,1\\r\\n204,47,5\\r\\n217,48,2\\r\\n234,23,1\\r\\n314,5,1\\r\\n268,37,1\\r\\n219,22,2\\r\\n273,35,5\\r\\n300,8,3\\r\\n67,32,1\\r\\n243,24,3\\r\\n157,12,1\\r\\n175,6,4\\r\\n34,29,2\\r\\n85,24,3\\r\\n117,47,1\\r\\n291,23,4\\r\\n117,47,4\\r\\n74,42,4\\r\\n316,7,1\\r\\n147,35,5\\r\\n293,24,1\\r\\n111,44,2\\r\\n340,39,4\\r\\n84,31,2\\r\\n243,4,2\\r\\n24,12,5\\r\\n314,4,1\\r\\n230,15,1\\r\\n70,26,1\\r\\n58,31,5\\r\\n28,39,5\\r\\n260,23,4\\r\\n33,23,4\\r\\n145,3,5\\r\\n228,4,5\\r\\n21,25,4\\r\\n87,42,4\\r\\n199,34,5\\r\\n195,31,4\\r\\n327,42,4\\r\\n354,38,4\\r\\n330,7,5\\r\\n223,30,1\\r\\n167,35,3\\r\\n315,46,2\\r\\n52,40,1\\r\\n7,6,4\\r\\n207,17,4\\r\\n278,10,4\\r\\n125,3,5\\r\\n236,25,2\\r\\n97,14,3\\r\\n108,15,3\\r\\n323,15,4\\r\\n254,20,2\\r\\n122,47,2\\r\\n148,15,3\\r\\n208,20,4\\r\\n154,50,1\\r\\n317,17,1\\r\\n158,49,1\\r\\n226,49,3\\r\\n174,43,4\\r\\n202,1,1\\r\\n345,33,1\\r\\n218,28,3\\r\\n221,13,4\\r\\n104,34,2\\r\\n296,24,3\\r\\n78,33,1\\r\\n274,12,1\\r\\n302,28,1\\r\\n7,44,3\\r\\n14,4,2\\r\\n98,37,5\\r\\n114,8,3\\r\\n103,45,1\\r\\n146,27,4\\r\\n227,20,1\\r\\n299,17,3\\r\\n229,2,4\\r\\n176,3,2\\r\\n199,1,2\\r\\n15,2,1\\r\\n285,15,5\\r\\n8,13,3\\r\\n282,2,4\\r\\n171,25,4\\r\\n24,37,4\\r\\n192,11,3\\r\\n8,2,4\\r\\n220,16,5\\r\\n245,3,3\\r\\n14,6,4\\r\\n158,27,4\\r\\n201,17,2\\r\\n242,34,2\\r\\n82,45,2\\r\\n197,23,5\\r\\n109,6,4\\r\\n170,11,2\\r\\n111,46,2\\r\\n19,50,3\\r\\n122,15,3\\r\\n143,2,2\\r\\n202,27,3\\r\\n340,20,3\\r\\n150,7,2\\r\\n137,15,4\\r\\n238,13,5\\r\\n196,18,5\\r\\n149,36,1\\r\\n281,8,2\\r\\n127,27,1\\r\\n27,19,3\\r\\n284,7,1\\r\\n281,34,4\\r\\n95,8,3\\r\\n292,12,1\\r\\n292,24,4\\r\\n255,49,3\\r\\n191,20,4\\r\\n263,5,4\\r\\n294,21,4\\r\\n211,29,4\\r\\n34,33,3\\r\\n187,38,3\\r\\n137,14,4\\r\\n6,33,3\\r\\n29,23,5\\r\\n6,6,2\\r\\n281,28,5\\r\\n337,35,4\\r\\n35,26,2\\r\\n327,32,2\\r\\n108,28,2\\r\\n82,8,4\\r\\n337,35,1\\r\\n151,29,5\\r\\n331,18,3\\r\\n307,9,2\\r\\n66,37,4\\r\\n322,49,5\\r\\n86,45,2\\r\\n183,6,3\\r\\n131,10,4\\r\\n226,12,4\\r\\n347,14,4\\r\\n352,5,4\\r\\n21,47,2\\r\\n258,33,3\\r\\n63,19,5\\r\\n110,27,2\\r\\n117,49,3\\r\\n303,30,1\\r\\n210,27,1\\r\\n247,6,2\\r\\n290,21,5\\r\\n204,22,4\\r\\n323,26,1\\r\\n12,49,1\\r\\n277,44,3\\r\\n242,8,4\\r\\n263,31,3\\r\\n17,36,1\\r\\n103,13,4\\r\\n132,27,2\\r\\n53,23,3\\r\\n290,10,4\\r\\n45,9,4\\r\\n6,18,3\\r\\n328,41,4\\r\\n349,19,2\\r\\n100,33,5\\r\\n109,12,2\\r\\n257,22,1\\r\\n230,29,3\\r\\n112,42,1\\r\\n346,23,1\\r\\n144,14,1\\r\\n325,22,3\\r\\n260,36,4\\r\\n102,24,5\\r\\n323,16,2\\r\\n211,46,1\\r\\n61,26,5\\r\\n292,43,2\\r\\n179,31,4\\r\\n221,46,2\\r\\n299,22,2\\r\\n314,24,3\\r\\n149,15,1\\r\\n297,26,5\\r\\n145,30,4\\r\\n333,30,2\\r\\n146,6,3\\r\\n125,41,2\\r\\n108,22,2\\r\\n76,7,5\\r\\n342,37,2\\r\\n94,49,5\\r\\n43,26,5\\r\\n223,16,3\\r\\n276,11,2\\r\\n344,44,2\\r\\n125,10,4\\r\\n158,40,4\\r\\n92,36,2\\r\\n166,1,2\\r\\n257,45,4\\r\\n291,1,5\\r\\n127,42,4\\r\\n317,21,1\\r\\n52,9,3\\r\\n162,2,4\\r\\n6,7,5\\r\\n159,31,5\\r\\n111,29,5\\r\\n314,16,4\\r\\n284,46,5\\r\\n324,9,3\\r\\n326,2,3\\r\\n60,42,5\\r\\n226,46,2\\r\\n52,19,1\\r\\n2,46,5\\r\\n317,6,5\\r\\n76,24,2\\r\\n353,3,1\\r\\n29,50,1\\r\\n86,33,4\\r\\n250,7,5\\r\\n143,10,4\\r\\n142,41,1\\r\\n105,3,4\\r\\n322,28,1\\r\\n139,34,2\\r\\n79,29,2\\r\\n50,31,4\\r\\n268,15,3\\r\\n252,21,4\\r\\n229,14,5\\r\\n134,21,4\\r\\n103,46,4\\r\\n50,2,3\\r\\n186,27,2\\r\\n56,4,2\\r\\n74,45,4\\r\\n22,32,4\\r\\n289,7,2\\r\\n84,26,2\\r\\n204,10,4\\r\\n210,50,5\\r\\n108,42,3\\r\\n28,27,5\\r\\n269,29,3\\r\\n104,22,1\\r\\n268,41,2\\r\\n239,12,2\\r\\n103,46,2\\r\\n58,34,1\\r\\n33,15,3\\r\\n139,1,3\\r\\n71,45,2\\r\\n350,15,5\\r\\n66,6,3\\r\\n320,8,5\\r\\n140,34,5\\r\\n71,12,2\\r\\n274,43,1\\r\\n228,17,3\\r\\n82,22,1\\r\\n164,4,5\\r\\n309,44,1\\r\\n11,41,5\\r\\n106,19,3\\r\\n24,5,5\\r\\n175,41,2\\r\\n330,9,3\\r\\n212,18,2\\r\\n190,46,4\\r\\n189,47,4\\r\\n294,23,5\\r\\n300,32,3\\r\\n105,34,4\\r\\n192,48,5\\r\\n266,9,5\\r\\n59,35,1\\r\\n222,42,1\\r\\n175,26,5\\r\\n127,30,5\\r\\n294,44,3\\r\\n155,28,4\\r\\n107,3,5\\r\\n222,9,4\\r\\n31,36,4\\r\\n64,46,1\\r\\n216,11,2\\r\\n278,22,1\\r\\n345,17,2\\r\\n38,16,3\\r\\n33,23,5\\r\\n45,11,1\\r\\n166,35,3\\r\\n279,41,1\\r\\n116,26,1\\r\\n21,4,4\\r\\n10,37,1\\r\\n164,33,2\\r\\n274,2,5\\r\\n273,29,5\\r\\n118,9,5\\r\\n10,19,4\\r\\n62,19,4\\r\\n256,10,4\\r\\n135,7,4\\r\\n118,14,5\\r\\n282,38,1\\r\\n189,25,5\\r\\n197,19,5\\r\\n39,45,2\\r\\n8,41,4\\r\\n137,3,5\\r\\n26,38,4\\r\\n106,17,5\\r\\n309,19,4\\r\\n240,8,4\\r\\n350,13,2\\r\\n207,8,3\\r\\n350,43,3\\r\\n12,12,1\\r\\n60,15,3\\r\\n172,45,2\\r\\n3,44,4\\r\\n3,19,3\\r\\n289,33,2\\r\\n234,48,2\\r\\n143,32,2\\r\\n172,4,4\\r\\n106,16,2\\r\\n348,45,5\\r\\n31,46,4\\r\\n153,24,3\\r\\n222,23,5\\r\\n111,15,3\\r\\n209,20,4\\r\\n158,48,2\\r\\n43,32,4\\r\\n308,26,2\\r\\n67,22,4\\r\\n150,1,4\\r\\n302,4,2\\r\\n8,32,3\\r\\n78,34,2\\r\\n306,3,3\\r\\n256,15,4\\r\\n316,4,4\\r\\n200,36,5\\r\\n158,45,4\\r\\n243,30,1\\r\\n175,49,1\\r\\n221,20,3\\r\\n2,22,5\\r\\n29,34,1\\r\\n350,15,1\\r\\n189,22,1\\r\\n308,18,2\\r\\n267,40,2\\r\\n267,5,4\\r\\n83,3,1\\r\\n334,7,1\\r\\n44,31,1\\r\\n297,8,5\\r\\n102,18,5\\r\\n74,44,5\\r\\n134,41,3\\r\\n273,6,4\\r\\n179,45,5\\r\\n273,39,5\\r\\n258,23,2\\r\\n316,16,3\\r\\n246,7,1\\r\\n250,14,4\\r\\n70,18,4\\r\\n174,32,1\\r\\n24,14,3\\r\\n30,18,2\\r\\n229,35,5\\r\\n345,32,3\\r\\n156,13,2\\r\\n281,34,1\\r\\n127,17,1\\r\\n260,35,2\\r\\n271,6,2\\r\\n11,10,4\\r\\n141,24,3\\r\\n264,12,3\\r\\n221,38,2\\r\\n121,29,3\\r\\n242,9,1\\r\\n94,2,2\\r\\n292,41,5\\r\\n165,37,2\\r\\n120,27,3\\r\\n290,26,3\\r\\n337,16,1\\r\\n255,37,5\\r\\n189,42,5\\r\\n196,45,2\\r\\n311,30,4\\r\\n46,32,5\\r\\n31,25,5\\r\\n219,20,3\\r\\n107,3,4\\r\\n244,35,2\\r\\n257,5,1\\r\\n69,26,1\\r\\n258,48,2\\r\\n72,15,4\\r\\n340,26,2\\r\\n165,4,2\\r\\n142,9,4\\r\\n125,50,2\\r\\n187,8,4\\r\\n171,34,1\\r\\n236,28,1\\r\\n195,34,4\\r\\n311,25,4\\r\\n12,15,2\\r\\n182,37,5\\r\\n211,48,4\\r\\n55,9,1\\r\\n344,17,2\\r\\n134,31,3\\r\\n139,46,2\\r\\n21,42,1\\r\\n338,46,1\\r\\n129,12,1\\r\\n322,26,3\\r\\n53,17,4\\r\\n163,1,5\\r\\n310,13,3\\r\\n47,47,3\\r\\n22,32,1\\r\\n289,29,2\\r\\n28,43,3\\r\\n161,31,5\\r\\n345,21,1\\r\\n246,38,1\\r\\n3,1,1\\r\\n73,11,5\\r\\n286,6,5\\r\\n240,16,2\\r\\n107,37,4\\r\\n6,4,1\\r\\n54,47,2\\r\\n16,9,3\\r\\n142,29,1\\r\\n339,4,4\\r\\n18,22,2\\r\\n125,15,2\\r\\n109,33,3\\r\\n282,33,2\\r\\n321,44,1\\r\\n162,39,3\\r\\n276,49,5\\r\\n329,40,3\\r\\n134,9,3\\r\\n246,20,4\\r\\n24,1,2\\r\\n13,6,1\\r\\n247,18,4\\r\\n221,41,4\\r\\n143,47,5\\r\\n250,15,4\\r\\n180,2,2\\r\\n264,34,3\\r\\n153,13,2\\r\\n19,42,2\\r\\n16,25,2\\r\\n222,34,1\\r\\n52,44,4\\r\\n172,17,5\\r\\n221,46,2\\r\\n249,45,3\\r\\n69,20,5\\r\\n267,40,4\\r\\n204,41,5\\r\\n14,1,2\\r\\n46,14,4\\r\\n75,31,3\\r\\n194,17,3\\r\\n57,8,2\\r\\n47,38,2\\r\\n280,3,5\\r\\n2,15,5\\r\\n296,3,3\\r\\n151,34,3\\r\\n47,13,2\\r\\n33,3,5\\r\\n71,16,4\\r\\n117,3,5\\r\\n139,10,1\\r\\n166,15,1\\r\\n222,16,5\\r\\n158,5,4\\r\\n12,24,2\\r\\n74,35,3\\r\\n122,22,1\\r\\n32,6,4\\r\\n156,7,5\\r\\n172,41,4\\r\\n145,25,5\\r\\n314,31,5\\r\\n344,10,4\\r\\n257,7,3\\r\\n288,16,4\\r\\n36,45,4\\r\\n71,33,5\\r\\n118,4,2\\r\\n121,33,3\\r\\n352,15,5\\r\\n143,7,2\\r\\n66,46,5\\r\\n189,29,4\\r\\n317,40,4\\r\\n111,38,1\\r\\n60,20,2\\r\\n187,39,4\\r\\n274,32,4\\r\\n246,24,4\\r\\n85,50,4\\r\\n18,46,5\\r\\n293,43,2\\r\\n279,29,3\\r\\n232,18,1\\r\\n175,41,2\\r\\n158,11,2\\r\\n166,4,3\\r\\n129,14,4\\r\\n48,20,3\\r\\n126,36,4\\r\\n126,49,5\\r\\n78,6,4\\r\\n353,1,4\\r\\n206,38,5\\r\\n304,35,4\\r\\n285,38,4\\r\\n215,25,1\\r\\n134,15,5\\r\\n310,5,3\\r\\n34,24,4\\r\\n143,22,3\\r\\n122,3,4\\r\\n160,16,3\\r\\n248,46,1\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing utilized library\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ETgtLqE0rMW6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "#make the User_Id and Class_Id column as string data type\n",
        "#change Order_Rating column to float data type\n",
        "dataframe = pd.read_csv(\"/content/rec_data.csv\")\n",
        "dataframe[[\"User_Id\", \"Class_Id\"]] = dataframe[[\"User_Id\", \"Class_Id\"]].astype(str)\n",
        "dataframe[[\"Order_Rating\"]] = dataframe[[\"Order_Rating\"]].astype(float)\n",
        "dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9oiAY2gRqzgX",
        "outputId": "30036271-d839-4644-f381-1c2a7749cee2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    User_Id Class_Id  Order_Rating\n",
              "0       228        1           4.0\n",
              "1       263       28           4.0\n",
              "2       310        4           4.0\n",
              "3        72       27           1.0\n",
              "4       238       25           5.0\n",
              "..      ...      ...           ...\n",
              "995      34       24           4.0\n",
              "996     143       22           3.0\n",
              "997     122        3           4.0\n",
              "998     160       16           3.0\n",
              "999     248       46           1.0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd895866-ade9-4582-bd82-43db7b8fbeae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Id</th>\n",
              "      <th>Class_Id</th>\n",
              "      <th>Order_Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>228</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263</td>\n",
              "      <td>28</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>310</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>72</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>238</td>\n",
              "      <td>25</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>34</td>\n",
              "      <td>24</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>143</td>\n",
              "      <td>22</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>122</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>160</td>\n",
              "      <td>16</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>248</td>\n",
              "      <td>46</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd895866-ade9-4582-bd82-43db7b8fbeae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd895866-ade9-4582-bd82-43db7b8fbeae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd895866-ade9-4582-bd82-43db7b8fbeae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#group User_Id and Class_Id so there is no duplicate and calculate the mean for the Order_Rating\n",
        "#Make dictionary with column name as key and the data as value\n",
        "#Make the tensorslicedataset from the dictionary\n",
        "#map the slicedataset with only data that we're gonna use(User_Id, Class_Id, Order_Rating)\n",
        "inter_dict = dataframe.groupby([\"User_Id\", \"Class_Id\"])[\"Order_Rating\"].agg(np.mean).reset_index()\n",
        "inter_dict = {name: np.array(value) for name, value in inter_dict.items()}\n",
        "interaction = tf.data.Dataset.from_tensor_slices(inter_dict)\n",
        "\n",
        "#drop duplicate in Class_Id column\n",
        "#make dictionary\n",
        "#make tensorslicedataset from dictionary\n",
        "#map the slicedataset\n",
        "prod_dict = dataframe[[\"Class_Id\"]].drop_duplicates()\n",
        "prod_dict = {name: np.array(value) for name, value in prod_dict.items()}\n",
        "product = tf.data.Dataset.from_tensor_slices(prod_dict)\n",
        "\n",
        "interaction = interaction.map(lambda x: {\n",
        "    \"User_Id\": x[\"User_Id\"],\n",
        "    \"Class_Id\": x[\"Class_Id\"],\n",
        "    \"Order_Rating\": float(x[\"Order_Rating\"])\n",
        "})\n",
        "\n",
        "product = product.map(lambda x: x[\"Class_Id\"])"
      ],
      "metadata": {
        "id": "shrjKZfirllJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take User_Id and Class_Id from mapdataset\n",
        "user_ids = interaction.batch(100).map(lambda x: x[\"User_Id\"])\n",
        "product_ids = interaction.batch(100).map(lambda x: x[\"Class_Id\"])\n",
        "#make a list out of unique user_ids and product_ids\n",
        "unique_user = np.unique(np.concatenate(list(user_ids)))\n",
        "unique_product = np.unique(np.concatenate(list(product_ids)))"
      ],
      "metadata": {
        "id": "_JwE57PktmNG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the training and testing dataset and shuffle it\n",
        "tf.random.set_seed(42)\n",
        "shuffled = interaction.shuffle(100, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(800)\n",
        "test = shuffled.skip(800).take(164)\n",
        "\n",
        "cached_train = train.shuffle(100).batch(100)\n",
        "cached_test = test.batch(10).cache()\n"
      ],
      "metadata": {
        "id": "3RcNlX0Xv9Zz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(tfrs.models.Model):\n",
        "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    embed_dim = 32\n",
        "    #define product model, map string to indices and turn them into dense vectors with 32 dimension\n",
        "    self.product_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "          tf.keras.layers.StringLookup(vocabulary = unique_product, mask_token = None),\n",
        "          tf.keras.layers.Embedding(len(unique_product) + 1, embed_dim)\n",
        "    ])\n",
        "    #define user model\n",
        "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "          tf.keras.layers.StringLookup(vocabulary = unique_user, mask_token = None),\n",
        "          tf.keras.layers.Embedding(len(unique_user) + 1, embed_dim)\n",
        "    ])\n",
        "    #define rating model with dense layer with one output for rating prediction\n",
        "    self.rating_model = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "          tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "          tf.keras.layers.Dense(1),\n",
        "        ])\n",
        "    #define metrics for retrieval task with factorizedtopk\n",
        "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "          metrics = tfrs.metrics.FactorizedTopK(\n",
        "            candidates = product.batch(128).map(self.product_model), k = 50\n",
        "        )\n",
        "    )\n",
        "    #define metrics and loss for rating task with RMSE\n",
        "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "          loss = tf.keras.losses.MeanSquaredError(),\n",
        "          metrics = [tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "    self.retrieval_weight = retrieval_weight\n",
        "    self.rating_weight = rating_weight\n",
        "  ###function for predicting rating\n",
        "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "    user_embeddings = self.user_model(features[\"User_Id\"])\n",
        "    product_embeddings = self.product_model(features[\"Class_Id\"])\n",
        "    return(\n",
        "        user_embeddings, product_embeddings, self.rating_model(tf.concat([user_embeddings, product_embeddings], axis = 1),)\n",
        "    )\n",
        "  ###function for computing loss and metrics\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training = False) -> tf.Tensor:\n",
        "    ratings = features.pop(\"Order_Rating\")\n",
        "    user_embeddings, product_embeddings, rating_predictions = self(features)\n",
        "\n",
        "    retrieval_loss = self.retrieval_task(user_embeddings, product_embeddings)\n",
        "    rating_loss = self.rating_task(\n",
        "        labels = ratings,\n",
        "        predictions = rating_predictions\n",
        "    )\n",
        "    return (self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss)"
      ],
      "metadata": {
        "id": "PtHDHBylwvHr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model with taking account rating and retrieval using gradient descent optmizer\n",
        "model = Model(rating_weight=1, retrieval_weight=1)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "YRioJI-jxTwR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=50)\n",
        "metrics = model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"top 5 accuracy: {metrics['factorized_top_k/top_5_categorical_accuracy']:.3f}.\")\n",
        "print(f\"RMSE Ranking: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXrVLTmbxX3y",
        "outputId": "06a742c4-e7c1-45d9-85f0-cf2d8fa1fbf6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 2s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0775 - factorized_top_k/top_10_categorical_accuracy: 0.1650 - factorized_top_k/top_50_categorical_accuracy: 0.9875 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 2.1428 - loss: 464.9640 - regularization_loss: 0.0000e+00 - total_loss: 464.9640\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.4475 - factorized_top_k/top_10_categorical_accuracy: 0.7525 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.5990 - loss: 459.8395 - regularization_loss: 0.0000e+00 - total_loss: 459.8395\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.6525 - factorized_top_k/top_10_categorical_accuracy: 0.8925 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.4556 - loss: 444.3122 - regularization_loss: 0.0000e+00 - total_loss: 444.3122\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.7613 - factorized_top_k/top_10_categorical_accuracy: 0.9425 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3588 - loss: 404.0203 - regularization_loss: 0.0000e+00 - total_loss: 404.0203\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 51ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.7912 - factorized_top_k/top_10_categorical_accuracy: 0.9725 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.4695 - loss: 351.1018 - regularization_loss: 0.0000e+00 - total_loss: 351.1018\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0162 - factorized_top_k/top_5_categorical_accuracy: 0.8438 - factorized_top_k/top_10_categorical_accuracy: 0.9850 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3810 - loss: 307.1620 - regularization_loss: 0.0000e+00 - total_loss: 307.1620\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0162 - factorized_top_k/top_5_categorical_accuracy: 0.8800 - factorized_top_k/top_10_categorical_accuracy: 0.9950 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3391 - loss: 278.2265 - regularization_loss: 0.0000e+00 - total_loss: 278.2265\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0463 - factorized_top_k/top_5_categorical_accuracy: 0.8913 - factorized_top_k/top_10_categorical_accuracy: 0.9975 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3613 - loss: 260.3686 - regularization_loss: 0.0000e+00 - total_loss: 260.3686\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0562 - factorized_top_k/top_5_categorical_accuracy: 0.9062 - factorized_top_k/top_10_categorical_accuracy: 0.9987 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3090 - loss: 249.1672 - regularization_loss: 0.0000e+00 - total_loss: 249.1672\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0587 - factorized_top_k/top_5_categorical_accuracy: 0.8988 - factorized_top_k/top_10_categorical_accuracy: 0.9987 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2632 - loss: 240.0111 - regularization_loss: 0.0000e+00 - total_loss: 240.0111\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0763 - factorized_top_k/top_5_categorical_accuracy: 0.8950 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2170 - loss: 234.9801 - regularization_loss: 0.0000e+00 - total_loss: 234.9801\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 1s 73ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0825 - factorized_top_k/top_5_categorical_accuracy: 0.9100 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.3092 - loss: 231.4924 - regularization_loss: 0.0000e+00 - total_loss: 231.4924\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 1s 70ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0787 - factorized_top_k/top_5_categorical_accuracy: 0.9025 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2310 - loss: 227.7561 - regularization_loss: 0.0000e+00 - total_loss: 227.7561\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 1s 65ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1050 - factorized_top_k/top_5_categorical_accuracy: 0.9062 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.1919 - loss: 226.0764 - regularization_loss: 0.0000e+00 - total_loss: 226.0764\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1000 - factorized_top_k/top_5_categorical_accuracy: 0.9075 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.1811 - loss: 222.6934 - regularization_loss: 0.0000e+00 - total_loss: 222.6934\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0975 - factorized_top_k/top_5_categorical_accuracy: 0.9100 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.0494 - loss: 220.4289 - regularization_loss: 0.0000e+00 - total_loss: 220.4289\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1100 - factorized_top_k/top_5_categorical_accuracy: 0.9137 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.2004 - loss: 223.9619 - regularization_loss: 0.0000e+00 - total_loss: 223.9619\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1125 - factorized_top_k/top_5_categorical_accuracy: 0.9150 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.0044 - loss: 219.9791 - regularization_loss: 0.0000e+00 - total_loss: 219.9791\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 52ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1037 - factorized_top_k/top_5_categorical_accuracy: 0.9087 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.9824 - loss: 217.9655 - regularization_loss: 0.0000e+00 - total_loss: 217.9655\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1112 - factorized_top_k/top_5_categorical_accuracy: 0.9100 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.1062 - loss: 217.3319 - regularization_loss: 0.0000e+00 - total_loss: 217.3319\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1213 - factorized_top_k/top_5_categorical_accuracy: 0.9112 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.9450 - loss: 215.2181 - regularization_loss: 0.0000e+00 - total_loss: 215.2181\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1088 - factorized_top_k/top_5_categorical_accuracy: 0.9137 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.0010 - loss: 217.6739 - regularization_loss: 0.0000e+00 - total_loss: 217.6739\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1100 - factorized_top_k/top_5_categorical_accuracy: 0.9150 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.7732 - loss: 214.1531 - regularization_loss: 0.0000e+00 - total_loss: 214.1531\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1312 - factorized_top_k/top_5_categorical_accuracy: 0.9175 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.8992 - loss: 215.4031 - regularization_loss: 0.0000e+00 - total_loss: 215.4031\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1088 - factorized_top_k/top_5_categorical_accuracy: 0.9112 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.8533 - loss: 211.5308 - regularization_loss: 0.0000e+00 - total_loss: 211.5308\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1163 - factorized_top_k/top_5_categorical_accuracy: 0.9112 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.8108 - loss: 213.8489 - regularization_loss: 0.0000e+00 - total_loss: 213.8489\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 53ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1150 - factorized_top_k/top_5_categorical_accuracy: 0.9087 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.7324 - loss: 213.0476 - regularization_loss: 0.0000e+00 - total_loss: 213.0476\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 54ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1250 - factorized_top_k/top_5_categorical_accuracy: 0.9175 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.8690 - loss: 214.8935 - regularization_loss: 0.0000e+00 - total_loss: 214.8935\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1138 - factorized_top_k/top_5_categorical_accuracy: 0.9187 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.6567 - loss: 212.6518 - regularization_loss: 0.0000e+00 - total_loss: 212.6518\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 59ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1150 - factorized_top_k/top_5_categorical_accuracy: 0.9150 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.5792 - loss: 214.2743 - regularization_loss: 0.0000e+00 - total_loss: 214.2743\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1163 - factorized_top_k/top_5_categorical_accuracy: 0.9150 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.7294 - loss: 212.9324 - regularization_loss: 0.0000e+00 - total_loss: 212.9324\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1138 - factorized_top_k/top_5_categorical_accuracy: 0.9200 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.5651 - loss: 212.1543 - regularization_loss: 0.0000e+00 - total_loss: 212.1543\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 59ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1300 - factorized_top_k/top_5_categorical_accuracy: 0.9137 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.4790 - loss: 211.7217 - regularization_loss: 0.0000e+00 - total_loss: 211.7217\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1112 - factorized_top_k/top_5_categorical_accuracy: 0.9225 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.5860 - loss: 210.8857 - regularization_loss: 0.0000e+00 - total_loss: 210.8857\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 59ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1112 - factorized_top_k/top_5_categorical_accuracy: 0.9225 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.5691 - loss: 209.9031 - regularization_loss: 0.0000e+00 - total_loss: 209.9031\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1213 - factorized_top_k/top_5_categorical_accuracy: 0.9162 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.5146 - loss: 211.2332 - regularization_loss: 0.0000e+00 - total_loss: 211.2332\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1238 - factorized_top_k/top_5_categorical_accuracy: 0.9262 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3837 - loss: 211.6084 - regularization_loss: 0.0000e+00 - total_loss: 211.6084\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1338 - factorized_top_k/top_5_categorical_accuracy: 0.9225 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3590 - loss: 211.1152 - regularization_loss: 0.0000e+00 - total_loss: 211.1152\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1187 - factorized_top_k/top_5_categorical_accuracy: 0.9187 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3955 - loss: 209.8742 - regularization_loss: 0.0000e+00 - total_loss: 209.8742\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1138 - factorized_top_k/top_5_categorical_accuracy: 0.9237 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3713 - loss: 210.0426 - regularization_loss: 0.0000e+00 - total_loss: 210.0426\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1350 - factorized_top_k/top_5_categorical_accuracy: 0.9212 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3278 - loss: 209.5760 - regularization_loss: 0.0000e+00 - total_loss: 209.5760\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 59ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1400 - factorized_top_k/top_5_categorical_accuracy: 0.9312 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.2783 - loss: 210.4019 - regularization_loss: 0.0000e+00 - total_loss: 210.4019\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1225 - factorized_top_k/top_5_categorical_accuracy: 0.9162 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.2734 - loss: 206.9282 - regularization_loss: 0.0000e+00 - total_loss: 206.9282\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1163 - factorized_top_k/top_5_categorical_accuracy: 0.9150 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3288 - loss: 208.4489 - regularization_loss: 0.0000e+00 - total_loss: 208.4489\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 57ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1262 - factorized_top_k/top_5_categorical_accuracy: 0.9200 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.3207 - loss: 209.3274 - regularization_loss: 0.0000e+00 - total_loss: 209.3274\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 60ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1312 - factorized_top_k/top_5_categorical_accuracy: 0.9237 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.2683 - loss: 209.0642 - regularization_loss: 0.0000e+00 - total_loss: 209.0642\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1338 - factorized_top_k/top_5_categorical_accuracy: 0.9250 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.2557 - loss: 210.4564 - regularization_loss: 0.0000e+00 - total_loss: 210.4564\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 56ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1287 - factorized_top_k/top_5_categorical_accuracy: 0.9225 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.2256 - loss: 209.4414 - regularization_loss: 0.0000e+00 - total_loss: 209.4414\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 58ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1200 - factorized_top_k/top_5_categorical_accuracy: 0.9225 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.1938 - loss: 207.7353 - regularization_loss: 0.0000e+00 - total_loss: 207.7353\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 55ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1163 - factorized_top_k/top_5_categorical_accuracy: 0.9200 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 0.2804 - loss: 206.9244 - regularization_loss: 0.0000e+00 - total_loss: 206.9244\n",
            "17/17 [==============================] - 3s 101ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0061 - factorized_top_k/top_5_categorical_accuracy: 0.0854 - factorized_top_k/top_10_categorical_accuracy: 0.1585 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - root_mean_squared_error: 1.6824 - loss: 31.4902 - regularization_loss: 0.0000e+00 - total_loss: 31.4902\n",
            "top 5 accuracy: 0.085.\n",
            "RMSE Ranking: 1.682.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the retrieval method and then save the model\n",
        "retrieval = tfrs.layers.factorized_top_k.ScaNN(model.user_model, k= 3, num_leaves = 10)\n",
        "retrieval.index_from_dataset(\n",
        "    tf.data.Dataset.zip((product.batch(5), product.batch(5).map(model.product_model))))\n",
        "_ = retrieval(np.array([\"29\"]))\n",
        "tf.saved_model.save(retrieval, \"/content/sample_data/Model\", options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC7i57qfxqXH",
        "outputId": "355064e9-a0d2-45e2-d213-12b9422c3f78"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/sample_data/Model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/sample_data/Model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load = tf.saved_model.load(\"/content/sample_data/Model\")"
      ],
      "metadata": {
        "id": "M6l2y3P_zLnV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating, suggestion = load(np.array([\"110\"]))\n",
        "print(rating)\n",
        "print(suggestion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ5Vm4K73x2G",
        "outputId": "34970693-6a77-42b7-ef75-ce5d6a6b46a7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[8.153923  3.3021047 2.9373307]], shape=(1, 3), dtype=float32)\n",
            "tf.Tensor([[b'27' b'32' b'50']], shape=(1, 3), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "76Z9RgBv3_k6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}